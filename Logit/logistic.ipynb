{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to keep things in order, and to avoid to copy and paste everytime our functions if we want to use them in more than one folder,\n",
    "#we can temporarily use this library. \n",
    "import sys\n",
    "\n",
    "#in this way Python will search the implementations also in the path '../HelperFunctions'\n",
    "sys.path.insert(0, '../HelperFunctions')\n",
    "sys.path.insert(0, '../pre-processing/Clean_Data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "from common_functions import *\n",
    "from counters import *\n",
    "from replace import *\n",
    "from regressors import batch_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "yb, input_data, ids = load_csv_data(\"../data/train.csv\", sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this will surely be deleted, in this way we are sure that original_data is the original version of the data and we don't have\n",
    "#to load them again\n",
    "from copy import deepcopy\n",
    "originalData = deepcopy(input_data)\n",
    "originalY = deepcopy(yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions from lab 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sig(t):\n",
    "#     \"\"\"apply sigmoid function on t.\"\"\"\n",
    "#     if t > 0:\n",
    "#         return 1 / (1 + np.exp(-t))\n",
    "#     else:\n",
    "#         return np.exp(t) / (1 + np.exp(t))\n",
    "\n",
    "# sigmoid = np.vectorize(sig)\n",
    "\n",
    "def sigmoid(t):\n",
    "     return .5*(1+np.tanh(.5 * t))\n",
    "\n",
    "def calculate_loss(y, tx, w):\n",
    "    \"\"\"compute the cost by negative log likelihood.\"\"\"\n",
    "    pred = sigmoid(tx.dot(w))\n",
    "    correctZero = 1e-7\n",
    "    loss = np.sum((1 - y) * np.log(1 - pred + correctZero) + y * np.log(pred + correctZero))\n",
    "    #return np.squeeze(- loss)\n",
    "    return -loss/y.shape[0]\n",
    "\n",
    "\n",
    "def calculate_gradient(y, tx, w):\n",
    "    \"\"\"compute the gradient of loss.\"\"\"\n",
    "    pred = sigmoid(tx.dot(w))\n",
    "    grad = tx.T.dot(pred - y)\n",
    "    return grad/y.shape[0]\n",
    "\n",
    "def learning_by_gradient_descent(y, tx, w, gamma):\n",
    "    \"\"\"\n",
    "    Do one step of gradient descen using logistic regression.\n",
    "    Return the loss and the updated w.\n",
    "    \"\"\"\n",
    "    #batch = next(batch_iter(y, tx, 32))\n",
    "    #minibatch_y, minibatch_tx = batch[0], batch[1]\n",
    "    grad = calculate_gradient(y, tx, w)\n",
    "    loss = calculate_loss(y, tx, w)\n",
    "    w = w - gamma * grad\n",
    "    return loss, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation of tx\n",
    "\n",
    "input_data = deepcopy(originalData)\n",
    "print(input_data.shape)\n",
    "#Clean the dataset\n",
    "numInvalidValues = countInvalid(input_data,-999)\n",
    "idxCols = np.where(numInvalidValues>0)[0]\n",
    "input_data = replaceWithZero(input_data,-999,idxCols)\n",
    "\n",
    "#standardize\n",
    "tx,_,_ = standardize(input_data)\n",
    "\n",
    "#add ones\n",
    "tx = np.c_[np.ones((yb.shape[0], 1)), tx]\n",
    "y = yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first tries with gradient descent\n",
    "\n",
    "Y, TX = sample_data(y, tx, 10, 500)\n",
    "max_iter = 10000\n",
    "w = np.zeros(tx.shape[1])\n",
    "gamma = 0.0005\n",
    "loss0 = 0\n",
    "print(TX.shape)\n",
    "\n",
    "for iter in range(max_iter):\n",
    "    wold = w\n",
    "    loss, w = learning_by_gradient_descent(Y, TX, w, gamma)\n",
    "\n",
    "    if iter%100==0:\n",
    "        wnew = w\n",
    "        print(f'Iter = {iter}, Loss = {loss}, |wold - wnew| = {np.linalg.norm(wold-wnew)}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to generate a submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WWW = w "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx, test_data, ids = load_csv_data(\"../data/test.csv\", sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to preprocess the test_data as we preprocessed the train data\n",
    "\n",
    "numInvalidValues = countInvalid(test_data,-999)\n",
    "idxCols = np.where(numInvalidValues>0)[0]\n",
    "test_data = replaceWithZero(test_data,-999,idxCols)\n",
    "txTest,_,_ = standardize(test_data)\n",
    "txTest = np.c_[np.ones((xxx.shape[0], 1)), txTest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict_labels(WWW, txTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_submission(ids, y_pred, 'submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Same things with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../pre-processing/PCA/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 30)\n",
      "(250000,)\n"
     ]
    }
   ],
   "source": [
    "from pca_functions import PCAWithCovariance\n",
    "\n",
    "input_data = deepcopy(originalData)\n",
    "y = deepcopy(originalY)\n",
    "print(input_data.shape)\n",
    "print(y.shape)\n",
    "numInvalidValues = countInvalid(input_data,-999)\n",
    "idxCols = np.where(numInvalidValues>0)[0]\n",
    "input_data = replaceWithZero(input_data,-999,idxCols)\n",
    "input_data,_,_ = standardize(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating the principal components\n",
    "\n",
    "_,eV = PCAWithCovariance(input_data)\n",
    "\n",
    "N = 4 #num p. components\n",
    "components = np.empty(input_data.shape[0])\n",
    "for i in range(N):\n",
    "    components = np.c_[components, input_data.dot(eV[:,i])]\n",
    "    \n",
    "#tx = np.c_[np.ones(input_data.shape[0]), components]\n",
    "tx = components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 5)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y, TX = sample_data(y, tx, 1, 2000)\n",
    "TX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter = 0, Loss = 0.6931469805599656, |wold - wnew| = 0.0034411324058047743\n",
      "Iter = 100, Loss = 0.5487411800655818, |wold - wnew| = 0.002110866374208986\n",
      "Iter = 200, Loss = 0.4818058566295827, |wold - wnew| = 0.001596908331352765\n",
      "Iter = 300, Loss = 0.4397917103253635, |wold - wnew| = 0.001318663569680761\n",
      "Iter = 400, Loss = 0.40984355808032197, |wold - wnew| = 0.0011365644752609491\n",
      "Iter = 500, Loss = 0.38699895760991754, |wold - wnew| = 0.0010053654063913243\n",
      "Iter = 600, Loss = 0.3687974523666116, |wold - wnew| = 0.0009053794088694249\n",
      "Iter = 700, Loss = 0.35383642377823926, |wold - wnew| = 0.0008262998475352955\n",
      "Iter = 800, Loss = 0.34124304200179606, |wold - wnew| = 0.0007620532945561591\n",
      "Iter = 900, Loss = 0.33044035059980137, |wold - wnew| = 0.0007087616304030384\n",
      "Iter = 1000, Loss = 0.3210295768029005, |wold - wnew| = 0.0006638044859590974\n",
      "Iter = 1100, Loss = 0.3127253201200707, |wold - wnew| = 0.0006253369951454438\n",
      "Iter = 1200, Loss = 0.30531739667893093, |wold - wnew| = 0.0005920192466564274\n",
      "Iter = 1300, Loss = 0.2986472016726903, |wold - wnew| = 0.0005628538985142379\n",
      "Iter = 1400, Loss = 0.2925924680347789, |wold - wnew| = 0.000537083504490485\n",
      "Iter = 1500, Loss = 0.28705712252676246, |wold - wnew| = 0.0005141229275010999\n",
      "Iter = 1600, Loss = 0.2819643700771334, |wold - wnew| = 0.0004935134150617776\n",
      "Iter = 1700, Loss = 0.2772519052866345, |wold - wnew| = 0.0004748905814624148\n",
      "Iter = 1800, Loss = 0.27286857706617756, |wold - wnew| = 0.00045796160180033293\n",
      "Iter = 1900, Loss = 0.2687720673327423, |wold - wnew| = 0.00044248866666131567\n",
      "Iter = 2000, Loss = 0.26492726538219724, |wold - wnew| = 0.0004282767846472678\n",
      "Iter = 2100, Loss = 0.2613050809175661, |wold - wnew| = 0.00041516466112517363\n",
      "Iter = 2200, Loss = 0.25788148940624844, |wold - wnew| = 0.0004030177894301042\n",
      "Iter = 2300, Loss = 0.2546366745972524, |wold - wnew| = 0.0003917231567351853\n",
      "Iter = 2400, Loss = 0.25155421958045987, |wold - wnew| = 0.00038118514398559594\n",
      "Iter = 2500, Loss = 0.2486203660622169, |wold - wnew| = 0.0003713223195492051\n",
      "Iter = 2600, Loss = 0.24582338500055725, |wold - wnew| = 0.00036206490918948563\n",
      "Iter = 2700, Loss = 0.24315308552369913, |wold - wnew| = 0.0003533527830758051\n",
      "Iter = 2800, Loss = 0.24060045926293203, |wold - wnew| = 0.0003451338417769984\n",
      "Iter = 2900, Loss = 0.23815743571194442, |wold - wnew| = 0.0003373627128333972\n",
      "Iter = 3000, Loss = 0.23581671733317247, |wold - wnew| = 0.00032999969104772987\n",
      "Iter = 3100, Loss = 0.23357166663350837, |wold - wnew| = 0.0003230098714791741\n",
      "Iter = 3200, Loss = 0.23141622489917119, |wold - wnew| = 0.00031636243587609893\n",
      "Iter = 3300, Loss = 0.2293448495240812, |wold - wnew| = 0.0003100300620986958\n",
      "Iter = 3400, Loss = 0.22735246226210876, |wold - wnew| = 0.00030398843273216975\n",
      "Iter = 3500, Loss = 0.2254344042083783, |wold - wnew| = 0.00029821582417108723\n",
      "Iter = 3600, Loss = 0.22358639532168437, |wold - wnew| = 0.0002926927613454578\n",
      "Iter = 3700, Loss = 0.221804497391192, |wold - wnew| = 0.00028740172627674465\n",
      "Iter = 3800, Loss = 0.2200850798921208, |wold - wnew| = 0.00028232691099314513\n",
      "Iter = 3900, Loss = 0.21842478845092494, |wold - wnew| = 0.0002774540071757659\n",
      "Iter = 4000, Loss = 0.21682051575840022, |wold - wnew| = 0.0002727700263571892\n",
      "Iter = 4100, Loss = 0.21526937484560998, |wold - wnew| = 0.0002682631456385751\n",
      "Iter = 4200, Loss = 0.21376867467427263, |wold - wnew| = 0.0002639225748150982\n",
      "Iter = 4300, Loss = 0.21231589801905087, |wold - wnew| = 0.00025973844152717336\n",
      "Iter = 4400, Loss = 0.21090868163022686, |wold - wnew| = 0.00025570169165176385\n",
      "Iter = 4500, Loss = 0.20954479867261847, |wold - wnew| = 0.0002518040026225634\n",
      "Iter = 4600, Loss = 0.20822214341075002, |wold - wnew| = 0.00024803770775956336\n",
      "Iter = 4700, Loss = 0.20693871809053563, |wold - wnew| = 0.00024439573000369904\n",
      "Iter = 4800, Loss = 0.20569262192349932, |wold - wnew| = 0.00024087152371479945\n",
      "Iter = 4900, Loss = 0.2044820420296071, |wold - wnew| = 0.00023745902340188075\n",
      "Iter = 5000, Loss = 0.2033052461614872, |wold - wnew| = 0.0002341525984343769\n",
      "Iter = 5100, Loss = 0.2021605769817822, |wold - wnew| = 0.00023094701292767766\n",
      "Iter = 5200, Loss = 0.20104644765549085, |wold - wnew| = 0.00022783739011795166\n",
      "Iter = 5300, Loss = 0.19996133850210868, |wold - wnew| = 0.0002248191806449668\n",
      "Iter = 5400, Loss = 0.1989037944673125, |wold - wnew| = 0.0002218881342413773\n",
      "Iter = 5500, Loss = 0.19787242318314224, |wold - wnew| = 0.00021904027440773776\n",
      "Iter = 5600, Loss = 0.19686589343375635, |wold - wnew| = 0.00021627187570132393\n",
      "Iter = 5700, Loss = 0.19588293385897845, |wold - wnew| = 0.00021357944332507767\n",
      "Iter = 5800, Loss = 0.19492233177400398, |wold - wnew| = 0.00021095969474528635\n",
      "Iter = 5900, Loss = 0.19398293201917874, |wold - wnew| = 0.00020840954310163227\n",
      "Iter = 6000, Loss = 0.19306363576558344, |wold - wnew| = 0.00020592608220241487\n",
      "Iter = 6100, Loss = 0.19216339925347742, |wold - wnew| = 0.0002035065729292838\n",
      "Iter = 6200, Loss = 0.19128123241967968, |wold - wnew| = 0.0002011484308957409\n",
      "Iter = 6300, Loss = 0.1904161974305228, |wold - wnew| = 0.000198849215221428\n",
      "Iter = 6400, Loss = 0.18956740709358588, |wold - wnew| = 0.0001966066183052895\n",
      "Iter = 6500, Loss = 0.18873402318004712, |wold - wnew| = 0.00019441845649123416\n",
      "Iter = 6600, Loss = 0.18791525465293396, |wold - wnew| = 0.00019228266153631227\n",
      "Iter = 6700, Loss = 0.18711035582407337, |wold - wnew| = 0.00019019727279738876\n",
      "Iter = 6800, Loss = 0.18631862445396463, |wold - wnew| = 0.0001881604300665259\n",
      "Iter = 6900, Loss = 0.18553939982272788, |wold - wnew| = 0.00018617036699099677\n",
      "Iter = 7000, Loss = 0.1847720607803764, |wold - wnew| = 0.0001842254050210539\n",
      "Iter = 7100, Loss = 0.18401602380967375, |wold - wnew| = 0.00018232394783619955\n",
      "Iter = 7200, Loss = 0.18327074111127684, |wold - wnew| = 0.0001804644762039688\n",
      "Iter = 7300, Loss = 0.1825356987384109, |wold - wnew| = 0.00017864554323265334\n",
      "Iter = 7400, Loss = 0.18181041479099969, |wold - wnew| = 0.00017686576998014145\n",
      "Iter = 7500, Loss = 0.18109443768027103, |wold - wnew| = 0.00017512384139161354\n",
      "Iter = 7600, Loss = 0.18038734446700044, |wold - wnew| = 0.00017341850253097161\n",
      "Iter = 7700, Loss = 0.17968873928925844, |wold - wnew| = 0.000171748555085887\n",
      "Iter = 7800, Loss = 0.17899825184677318, |wold - wnew| = 0.00017011285411949262\n",
      "Iter = 7900, Loss = 0.17831553596765684, |wold - wnew| = 0.00016851030505036832\n",
      "Iter = 8000, Loss = 0.1776402682188038, |wold - wnew| = 0.00016693986084159376\n",
      "Iter = 8100, Loss = 0.17697214655900548, |wold - wnew| = 0.0001654005193782806\n",
      "Iter = 8200, Loss = 0.17631088902490416, |wold - wnew| = 0.00016389132102555783\n",
      "Iter = 8300, Loss = 0.1756562324264926, |wold - wnew| = 0.00016241134634465367\n",
      "Iter = 8400, Loss = 0.1750079310456801, |wold - wnew| = 0.00016095971395927488\n",
      "Iter = 8500, Loss = 0.17436575534902943, |wold - wnew| = 0.0001595355785615079\n",
      "Iter = 8600, Loss = 0.17372949068088905, |wold - wnew| = 0.00015813812904296663\n",
      "Iter = 8700, Loss = 0.17309893597305717, |wold - wnew| = 0.0001567665867434171\n",
      "Iter = 8800, Loss = 0.17247390245456695, |wold - wnew| = 0.000155420203810173\n",
      "Iter = 8900, Loss = 0.17185421238951204, |wold - wnew| = 0.00015409826165657014\n",
      "Iter = 9000, Loss = 0.17123969783471701, |wold - wnew| = 0.00015280006951403662\n",
      "Iter = 9100, Loss = 0.1706301994553233, |wold - wnew| = 0.00015152496307263696\n",
      "Iter = 9200, Loss = 0.17002556540597566, |wold - wnew| = 0.0001502723032000576\n",
      "Iter = 9300, Loss = 0.1694256502629369, |wold - wnew| = 0.0001490414747376989\n",
      "Iter = 9400, Loss = 0.16883031408616697, |wold - wnew| = 0.00014783188536502586\n",
      "Iter = 9500, Loss = 0.16823942152825447, |wold - wnew| = 0.00014664296453006817\n",
      "Iter = 9600, Loss = 0.1676528411014402, |wold - wnew| = 0.00014547416243966424\n",
      "Iter = 9700, Loss = 0.16707044449841743, |wold - wnew| = 0.00014432494910705343\n",
      "Iter = 9800, Loss = 0.16649210607802803, |wold - wnew| = 0.00014319481345228218\n",
      "Iter = 9900, Loss = 0.16591770240604364, |wold - wnew| = 0.00014208326245142785\n",
      "Iter = 10000, Loss = 0.16534711193966684, |wold - wnew| = 0.00014098982033319414\n",
      "Iter = 10100, Loss = 0.16478021478414942, |wold - wnew| = 0.0001399140278178918\n",
      "Iter = 10200, Loss = 0.1642168925419423, |wold - wnew| = 0.00013885544139537282\n",
      "Iter = 10300, Loss = 0.16365702824418463, |wold - wnew| = 0.00013781363264640746\n",
      "Iter = 10400, Loss = 0.16310050634292414, |wold - wnew| = 0.00013678818759255612\n",
      "Iter = 10500, Loss = 0.16254721275850978, |wold - wnew| = 0.00013577870608397858\n",
      "Iter = 10600, Loss = 0.1619970349828015, |wold - wnew| = 0.00013478480121873856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter = 10700, Loss = 0.16144986219220528, |wold - wnew| = 0.0001338060987894953\n",
      "Iter = 10800, Loss = 0.1609055854136311, |wold - wnew| = 0.00013284223675871884\n",
      "Iter = 10900, Loss = 0.16036409769043308, |wold - wnew| = 0.00013189286476177872\n",
      "Iter = 11000, Loss = 0.15982529424548067, |wold - wnew| = 0.00013095764363140603\n",
      "Iter = 11100, Loss = 0.15928907266462794, |wold - wnew| = 0.0001300362449486015\n",
      "Iter = 11200, Loss = 0.15875533306041997, |wold - wnew| = 0.00012912835061261926\n",
      "Iter = 11300, Loss = 0.15822397822416806, |wold - wnew| = 0.00012823365243398095\n",
      "Iter = 11400, Loss = 0.15769491376581868, |wold - wnew| = 0.00012735185174605847\n",
      "Iter = 11500, Loss = 0.15716804823293642, |wold - wnew| = 0.00012648265903277526\n",
      "Iter = 11600, Loss = 0.15664329321054493, |wold - wnew| = 0.00012562579357770776\n",
      "Iter = 11700, Loss = 0.15612056340212008, |wold - wnew| = 0.0001247809831264152\n",
      "Iter = 11800, Loss = 0.15559977667971656, |wold - wnew| = 0.000123947963566688\n",
      "Iter = 11900, Loss = 0.15508085411469547, |wold - wnew| = 0.0001231264786198049\n",
      "Iter = 12000, Loss = 0.15456372000579097, |wold - wnew| = 0.00012231627955156687\n",
      "Iter = 12100, Loss = 0.15404830184563686, |wold - wnew| = 0.00012151712488839586\n",
      "Iter = 12200, Loss = 0.15353453032474657, |wold - wnew| = 0.00012072878015476589\n",
      "Iter = 12300, Loss = 0.15302233926644201, |wold - wnew| = 0.00011995101761561725\n",
      "Iter = 12400, Loss = 0.1525116655747144, |wold - wnew| = 0.00011918361603354744\n",
      "Iter = 12500, Loss = 0.15200244918175662, |wold - wnew| = 0.00011842636043404704\n",
      "Iter = 12600, Loss = 0.15149463295163337, |wold - wnew| = 0.00011767904188417437\n",
      "Iter = 12700, Loss = 0.1509881625912376, |wold - wnew| = 0.00011694145727878487\n",
      "Iter = 12800, Loss = 0.15048298657373488, |wold - wnew| = 0.00011621340913412153\n",
      "Iter = 12900, Loss = 0.14997905603010706, |wold - wnew| = 0.00011549470539378466\n",
      "Iter = 13000, Loss = 0.14947632464275803, |wold - wnew| = 0.00011478515924030666\n",
      "Iter = 13100, Loss = 0.14897474855464063, |wold - wnew| = 0.00011408458891596507\n",
      "Iter = 13200, Loss = 0.1484742862633104, |wold - wnew| = 0.00011339281754846933\n",
      "Iter = 13300, Loss = 0.14797489851250578, |wold - wnew| = 0.00011270967298922698\n",
      "Iter = 13400, Loss = 0.14747654820785144, |wold - wnew| = 0.00011203498765014685\n",
      "Iter = 13500, Loss = 0.14697920029919226, |wold - wnew| = 0.00011136859835502435\n",
      "Iter = 13600, Loss = 0.14648282171404076, |wold - wnew| = 0.000110710346191658\n",
      "Iter = 13700, Loss = 0.14598738123152594, |wold - wnew| = 0.00011006007637247402\n",
      "Iter = 13800, Loss = 0.14549284943639698, |wold - wnew| = 0.0001094176380989031\n",
      "Iter = 13900, Loss = 0.14499919860058408, |wold - wnew| = 0.00010878288443313861\n",
      "Iter = 14000, Loss = 0.1445064026274845, |wold - wnew| = 0.00010815567217221903\n",
      "Iter = 14100, Loss = 0.1440144369697018, |wold - wnew| = 0.0001075358617295791\n",
      "Iter = 14200, Loss = 0.1435232785534468, |wold - wnew| = 0.00010692331702002211\n",
      "Iter = 14300, Loss = 0.14303290572069968, |wold - wnew| = 0.00010631790534930532\n",
      "Iter = 14400, Loss = 0.1425432981627416, |wold - wnew| = 0.00010571949730647753\n",
      "Iter = 14500, Loss = 0.14205443684587107, |wold - wnew| = 0.00010512796666402138\n",
      "Iter = 14600, Loss = 0.14156630397605288, |wold - wnew| = 0.00010454319027585359\n",
      "Iter = 14700, Loss = 0.14107888292420045, |wold - wnew| = 0.00010396504798637072\n",
      "Iter = 14800, Loss = 0.14059215818410195, |wold - wnew| = 0.00010339342253591778\n",
      "Iter = 14900, Loss = 0.14010611531990902, |wold - wnew| = 0.00010282819947557339\n",
      "Iter = 15000, Loss = 0.13962074091477486, |wold - wnew| = 0.00010226926707926072\n",
      "Iter = 15100, Loss = 0.13913602252215027, |wold - wnew| = 0.00010171651626483583\n",
      "Iter = 15200, Loss = 0.13865194862441502, |wold - wnew| = 0.00010116984051482927\n",
      "Iter = 15300, Loss = 0.13816850858539886, |wold - wnew| = 0.00010062913579863178\n",
      "Iter = 15400, Loss = 0.13768569261341856, |wold - wnew| = 0.00010009430050213401\n",
      "Iter = 15500, Loss = 0.13720349170522933, |wold - wnew| = 9.956523535425749e-05\n",
      "Iter = 15600, Loss = 0.13672189761197176, |wold - wnew| = 9.904184336168172e-05\n",
      "Iter = 15700, Loss = 0.13624090281505175, |wold - wnew| = 9.852402974134497e-05\n",
      "Iter = 15800, Loss = 0.13576050045151453, |wold - wnew| = 9.801170185625578e-05\n",
      "Iter = 15900, Loss = 0.13528068431052837, |wold - wnew| = 9.750476915633536e-05\n",
      "Iter = 16000, Loss = 0.13480144877249473, |wold - wnew| = 9.700314311835902e-05\n",
      "Iter = 16100, Loss = 0.13432278878377152, |wold - wnew| = 9.650673718818429e-05\n",
      "Iter = 16200, Loss = 0.13384469980597516, |wold - wnew| = 9.601546672605637e-05\n",
      "Iter = 16300, Loss = 0.13336717780706225, |wold - wnew| = 9.552924895346109e-05\n",
      "Iter = 16400, Loss = 0.1328902191946564, |wold - wnew| = 9.504800290181692e-05\n",
      "Iter = 16500, Loss = 0.13241382081363212, |wold - wnew| = 9.45716493614658e-05\n",
      "Iter = 16600, Loss = 0.13193797987582012, |wold - wnew| = 9.410011083465384e-05\n",
      "Iter = 16700, Loss = 0.13146269396864138, |wold - wnew| = 9.363331148835196e-05\n",
      "Iter = 16800, Loss = 0.13098796099780594, |wold - wnew| = 9.317117710966864e-05\n",
      "Iter = 16900, Loss = 0.13051377916311313, |wold - wnew| = 9.271363506149198e-05\n",
      "Iter = 17000, Loss = 0.1300401469322836, |wold - wnew| = 9.226061424161492e-05\n",
      "Iter = 17100, Loss = 0.12956706302581017, |wold - wnew| = 9.181204504007979e-05\n",
      "Iter = 17200, Loss = 0.1290945263515245, |wold - wnew| = 9.136785930176398e-05\n",
      "Iter = 17300, Loss = 0.12862253603309148, |wold - wnew| = 9.092799028580115e-05\n",
      "Iter = 17400, Loss = 0.12815109134007466, |wold - wnew| = 9.049237263099724e-05\n",
      "Iter = 17500, Loss = 0.1276801916950557, |wold - wnew| = 9.006094231787232e-05\n",
      "Iter = 17600, Loss = 0.12720983663505356, |wold - wnew| = 8.963363663473937e-05\n",
      "Iter = 17700, Loss = 0.1267400258051384, |wold - wnew| = 8.921039414522666e-05\n",
      "Iter = 17800, Loss = 0.12627075892562192, |wold - wnew| = 8.879115465310617e-05\n",
      "Iter = 17900, Loss = 0.12580203578571933, |wold - wnew| = 8.837585917224338e-05\n",
      "Iter = 18000, Loss = 0.12533385622173346, |wold - wnew| = 8.796444989691099e-05\n",
      "Iter = 18100, Loss = 0.12486622011273081, |wold - wnew| = 8.755687016992841e-05\n",
      "Iter = 18200, Loss = 0.12439912734476388, |wold - wnew| = 8.715306445494169e-05\n",
      "Iter = 18300, Loss = 0.12393257782176705, |wold - wnew| = 8.675297830852582e-05\n",
      "Iter = 18400, Loss = 0.1234665714414858, |wold - wnew| = 8.635655835281935e-05\n",
      "Iter = 18500, Loss = 0.12300110809127673, |wold - wnew| = 8.596375224999448e-05\n",
      "Iter = 18600, Loss = 0.122536187634056, |wold - wnew| = 8.557450867544437e-05\n",
      "Iter = 18700, Loss = 0.12207180990033051, |wold - wnew| = 8.518877729394157e-05\n",
      "Iter = 18800, Loss = 0.12160797469237321, |wold - wnew| = 8.480650873538485e-05\n",
      "Iter = 18900, Loss = 0.1211446817628879, |wold - wnew| = 8.442765457148596e-05\n",
      "Iter = 19000, Loss = 0.12068193082159286, |wold - wnew| = 8.405216729243122e-05\n",
      "Iter = 19100, Loss = 0.1202197215233161, |wold - wnew| = 8.368000028726419e-05\n",
      "Iter = 19200, Loss = 0.11975805346909067, |wold - wnew| = 8.3311107818427e-05\n",
      "Iter = 19300, Loss = 0.11929692620015385, |wold - wnew| = 8.294544500589016e-05\n",
      "Iter = 19400, Loss = 0.11883633920437806, |wold - wnew| = 8.258296780292027e-05\n",
      "Iter = 19500, Loss = 0.11837629190334249, |wold - wnew| = 8.2223632978029e-05\n",
      "Iter = 19600, Loss = 0.11791678366212772, |wold - wnew| = 8.186739809722255e-05\n",
      "Iter = 19700, Loss = 0.11745781378380592, |wold - wnew| = 8.151422150304524e-05\n",
      "Iter = 19800, Loss = 0.1169993815060463, |wold - wnew| = 8.116406229867716e-05\n",
      "Iter = 19900, Loss = 0.11654148601101653, |wold - wnew| = 8.081688032921447e-05\n",
      "Iter = 20000, Loss = 0.1160841264222414, |wold - wnew| = 8.04726361654539e-05\n",
      "Iter = 20100, Loss = 0.11562730181257572, |wold - wnew| = 8.013129108718804e-05\n",
      "Iter = 20200, Loss = 0.1151710111904673, |wold - wnew| = 7.979280706615769e-05\n",
      "Iter = 20300, Loss = 0.11471525352159988, |wold - wnew| = 7.945714675196793e-05\n",
      "Iter = 20400, Loss = 0.11426002771004709, |wold - wnew| = 7.912427345579536e-05\n",
      "Iter = 20500, Loss = 0.11380533263169249, |wold - wnew| = 7.879415113607693e-05\n",
      "Iter = 20600, Loss = 0.11335116710606755, |wold - wnew| = 7.846674438407228e-05\n",
      "Iter = 20700, Loss = 0.11289752991143036, |wold - wnew| = 7.81420184103537e-05\n",
      "Iter = 20800, Loss = 0.11244441980167298, |wold - wnew| = 7.781993902955683e-05\n",
      "Iter = 20900, Loss = 0.11199183548820381, |wold - wnew| = 7.750047264878892e-05\n",
      "Iter = 21000, Loss = 0.11153977565400132, |wold - wnew| = 7.718358625334564e-05\n",
      "Iter = 21100, Loss = 0.11108823895017156, |wold - wnew| = 7.68692473962961e-05\n",
      "Iter = 21200, Loss = 0.11063722401859155, |wold - wnew| = 7.655742418318622e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter = 21300, Loss = 0.11018672947398127, |wold - wnew| = 7.624808526302421e-05\n",
      "Iter = 21400, Loss = 0.10973675391388701, |wold - wnew| = 7.594119981483931e-05\n",
      "Iter = 21500, Loss = 0.10928729592892938, |wold - wnew| = 7.563673753614164e-05\n",
      "Iter = 21600, Loss = 0.10883835409882593, |wold - wnew| = 7.53346686340358e-05\n",
      "Iter = 21700, Loss = 0.1083899270031838, |wold - wnew| = 7.503496381218519e-05\n",
      "Iter = 21800, Loss = 0.10794201320224397, |wold - wnew| = 7.473759426122294e-05\n",
      "Iter = 21900, Loss = 0.10749461128194014, |wold - wnew| = 7.444253164806265e-05\n",
      "Iter = 22000, Loss = 0.1070477198230094, |wold - wnew| = 7.414974810808127e-05\n",
      "Iter = 22100, Loss = 0.10660133740628078, |wold - wnew| = 7.385921623184542e-05\n",
      "Iter = 22200, Loss = 0.10615546263875127, |wold - wnew| = 7.357090905924439e-05\n",
      "Iter = 22300, Loss = 0.10571009411989447, |wold - wnew| = 7.328480006651603e-05\n",
      "Iter = 22400, Loss = 0.10526523049481198, |wold - wnew| = 7.300086316177145e-05\n",
      "Iter = 22500, Loss = 0.1048208703998018, |wold - wnew| = 7.271907267197975e-05\n",
      "Iter = 22600, Loss = 0.10437701250545503, |wold - wnew| = 7.243940333680326e-05\n",
      "Iter = 22700, Loss = 0.10393365551395727, |wold - wnew| = 7.216183029942111e-05\n",
      "Iter = 22800, Loss = 0.10349079813246825, |wold - wnew| = 7.188632909939522e-05\n",
      "Iter = 22900, Loss = 0.10304843911967655, |wold - wnew| = 7.161287566289752e-05\n",
      "Iter = 23000, Loss = 0.10260657725159453, |wold - wnew| = 7.134144629673211e-05\n",
      "Iter = 23100, Loss = 0.10216521133628755, |wold - wnew| = 7.107201768013134e-05\n",
      "Iter = 23200, Loss = 0.10172434021859433, |wold - wnew| = 7.080456685621069e-05\n",
      "Iter = 23300, Loss = 0.10128396278114807, |wold - wnew| = 7.053907122780216e-05\n",
      "Iter = 23400, Loss = 0.10084407794122136, |wold - wnew| = 7.027550854670324e-05\n",
      "Iter = 23500, Loss = 0.10040468465390452, |wold - wnew| = 7.001385690879514e-05\n",
      "Iter = 23600, Loss = 0.09996578191730382, |wold - wnew| = 6.975409474840668e-05\n",
      "Iter = 23700, Loss = 0.099527368762028, |wold - wnew| = 6.94962008294722e-05\n",
      "Iter = 23800, Loss = 0.09908944427619752, |wold - wnew| = 6.924015423961393e-05\n",
      "Iter = 23900, Loss = 0.09865200757703997, |wold - wnew| = 6.898593438603402e-05\n",
      "Iter = 24000, Loss = 0.09821505782609317, |wold - wnew| = 6.873352098650469e-05\n",
      "Iter = 24100, Loss = 0.09777859423177204, |wold - wnew| = 6.848289406463563e-05\n",
      "Iter = 24200, Loss = 0.09734261605406641, |wold - wnew| = 6.823403394552953e-05\n",
      "Iter = 24300, Loss = 0.09690712258811265, |wold - wnew| = 6.798692124730954e-05\n",
      "Iter = 24400, Loss = 0.09647211318228721, |wold - wnew| = 6.77415368773638e-05\n",
      "Iter = 24500, Loss = 0.09603758722569782, |wold - wnew| = 6.74978620265175e-05\n",
      "Iter = 24600, Loss = 0.09560354415943251, |wold - wnew| = 6.725587816365375e-05\n",
      "Iter = 24700, Loss = 0.09516998346174614, |wold - wnew| = 6.701556703061168e-05\n",
      "Iter = 24800, Loss = 0.09473690466955495, |wold - wnew| = 6.677691063781189e-05\n",
      "Iter = 24900, Loss = 0.09430430735689464, |wold - wnew| = 6.653989125696165e-05\n"
     ]
    }
   ],
   "source": [
    "max_iter = 25000\n",
    "w = np.zeros(TX.shape[1])\n",
    "gamma = 0.005\n",
    "loss0 = 0\n",
    "for iter in range(max_iter):\n",
    "    wold = w\n",
    "    loss, w = learning_by_gradient_descent(Y, TX, w, gamma)\n",
    "\n",
    "    if iter%100==0:\n",
    "        wnew = w\n",
    "        print(f'Iter = {iter}, Loss = {loss}, |wold - wnew| = {np.linalg.norm(wold-wnew)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
