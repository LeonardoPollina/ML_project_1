{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comment\n",
    "\n",
    "This is the prototype of our future regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import time \n",
    "\n",
    "#to keep things in order, and to avoid to copy and paste everytime our functions if we want to use them in more than one folder,\n",
    "#we can temporarily use this library. \n",
    "import sys\n",
    "\n",
    "#in this way Python will search the implementations also in the path '../HelperFunctions'\n",
    "sys.path.insert(0, '../HelperFunctions')\n",
    "sys.path.insert(0, '../pre-processing/Clean_Data/')\n",
    "sys.path.insert(0, '../Logit')\n",
    "\n",
    "from proj1_helpers import *\n",
    "from common_functions import *\n",
    "from counters import *\n",
    "from remove import *\n",
    "from replace import *\n",
    "from regressors import *\n",
    "from CrossValidationFunctions import *\n",
    "from functions_logistic import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_logistic_labels(weights, data):\n",
    "    \"\"\"Generates class predictions given weights, and a test data matrix\"\"\"\n",
    "    y_pred = np.dot(data, weights)\n",
    "    y_pred=sigmoid(y_pred)\n",
    "    y_pred[np.where(y_pred <= 0.5)] = 0\n",
    "    y_pred[np.where(y_pred > 0.5)] = 1\n",
    "    \n",
    "    return y_pred\n",
    "            \n",
    "def convert_0_to_minus1(data):\n",
    "    data[data == 0]= -1\n",
    "    return data\n",
    "\n",
    "def convert_minus1_to_0(data):\n",
    "    data[data == -1]= 0\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def penalized_logistic_regression(y, tx, w, lambda_):\n",
    "    \"\"\"return the loss and gradient.\"\"\"\n",
    "    #num_samples = y.shape[0]\n",
    "    loss = calculate_logistic_loss(y, tx, w) + lambda_ * np.squeeze(w.T.dot(w))\n",
    "    gradient = calculate_logistic_gradient(y, tx, w) + 2 * lambda_ * w\n",
    "    return loss, gradient\n",
    "\n",
    "def learning_by_penalized_gradient(y, tx, w, gamma, lambda_):\n",
    "    \"\"\"\n",
    "    Do one step of gradient descent, using the penalized logistic regression.\n",
    "    Return the loss and updated w.\n",
    "    \"\"\"\n",
    "    loss, gradient = penalized_logistic_regression(y, tx, w, lambda_)\n",
    "    w -= gamma * gradient\n",
    "    return loss, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_hyperparam_with_CV(y, tx, lambdas, gamma, degrees, max_iter):\n",
    "\n",
    "    accuracy = np.zeros((len(lambdas), len(degrees)))\n",
    "    \n",
    "    for idx_lambda, lambda_ in enumerate(lambdas):\n",
    "        for idx_degree, degree in enumerate(degrees):\n",
    "                        \n",
    "            x_augmented = build_poly(tx, degree)\n",
    "            initial_w = np.ones((x_augmented.shape[1]))\n",
    "            \n",
    "            #regression with logistic method\n",
    "            k_indices = build_k_indices(y, 4, 1)\n",
    "            acc = cross_validation_with_logistic(y, x_augmented, k_indices, initial_w, gamma, lambda_, max_iter)        \n",
    "            accuracy[idx_lambda, idx_degree] = acc\n",
    "    \n",
    "    #find the best using the accuracy\n",
    "    max_acc = np.max(accuracy)\n",
    "    print('max acc = ',max_acc)\n",
    "    coordinates_best_parameter = np.where( accuracy == max_acc )\n",
    "    best_lambda_acc = lambdas[ coordinates_best_parameter[0][0] ]\n",
    "    best_degree_acc = degrees[ coordinates_best_parameter[0][1] ]\n",
    "\n",
    "    return best_lambda_acc, best_degree_acc, max_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_with_logistic(y, x, k_indices,initial_w, gamma, lambda_,max_iter):\n",
    "    \"\"\"CV regression according to the splitting in train/test given by k_indices.\n",
    "    \n",
    "    The returned quantities are the average of the quantities computed in the single folds\n",
    "    \n",
    "    return the accuracy\"\"\"\n",
    "    \n",
    "    folds = k_indices.shape[0]\n",
    "    accuracy = np.zeros(folds)\n",
    "    w=initial_w\n",
    "    \n",
    "    for k in range(folds):\n",
    "        \n",
    "        #split the data in train/test\n",
    "        idx = k_indices[k]\n",
    "        yte = y[idx]\n",
    "        if len( x.shape ) == 1:\n",
    "            xte = x[idx]\n",
    "        else:\n",
    "            xte = x[idx,:]\n",
    "            \n",
    "        ytr = np.delete(y,idx,0)\n",
    "        xtr = np.delete(x,idx,0)\n",
    "\n",
    "        #learning by penalized graient descent (with regularized logistic)\n",
    "        for iter_ in range(max_iter):\n",
    "            _, w = learning_by_penalized_gradient(ytr, xtr, w, gamma, lambda_)\n",
    "            \n",
    "        #accuracy\n",
    "        y_pred = predict_logistic_labels(w, xte)\n",
    "        accuracy[k] = np.sum(y_pred == yte) / len(yte)  \n",
    "   \n",
    "    return np.mean(accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeConstantColumns(data):\n",
    "    '''Remove columns which are constants from the data.\n",
    "       \n",
    "       Return data, idx_removed\n",
    "    '''\n",
    "    std = np.std(data, axis = 0)\n",
    "    idx_removed = np.where(std==0)[0]\n",
    "    if len(idx_removed >0 ):\n",
    "        data = np.delete(data,idx_removed,axis=1)\n",
    "    \n",
    "    return data, idx_removed\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data And Basic Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "yb, input_data, ids = load_csv_data(\"../data/train.csv\", sub_sample=False)\n",
    "_, test_data, ids_test = load_csv_data(\"../data/test.csv\", sub_sample=False)\n",
    "\n",
    "#this will surely be deleted, in this way we are sure that original_data is the original version of the data and we don't have\n",
    "#to load them again\n",
    "from copy import deepcopy\n",
    "originalData = deepcopy(input_data)\n",
    "originalY = deepcopy(yb)\n",
    "originalTest = deepcopy(test_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic step\n",
    "input_data = deepcopy(originalData)\n",
    "numInvalidValues=countInvalid(input_data, -999)\n",
    "idxCols = np.where(numInvalidValues>0)[0]\n",
    "input_data = replaceWithZero(input_data,-999,idxCols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jet division, removing constant columns, standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x0, x1, x2\n",
    "idx0 = np.where(input_data[:,22]==0)\n",
    "idx1 = np.where(input_data[:,22]==1)\n",
    "idx2 = np.where(input_data[:,22]>=2)\n",
    "\n",
    "x0 = input_data[idx0] \n",
    "x1 = input_data[idx1] \n",
    "x2 = input_data[idx2] \n",
    "\n",
    "y0 = yb[idx0]\n",
    "y1 = yb[idx1]\n",
    "y2 = yb[idx2]\n",
    "\n",
    "x0, idx_constants_removed0 = removeConstantColumns(x0)\n",
    "x1, idx_constants_removed1 = removeConstantColumns(x1)\n",
    "\n",
    "x0, mean_train0, std_train0 = standardize ( x0 )\n",
    "x1, mean_train1, std_train1 = standardize ( x1 )\n",
    "x2, mean_train2, std_train2 = standardize ( x2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y0 = convert_minus1_to_0(y0)\n",
    "y1 = convert_minus1_to_0(y1)\n",
    "y2 = convert_minus1_to_0(y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove HC columns\n",
    "\n",
    "Only if HC_flag = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "HC_flag = False\n",
    "\n",
    "if(HC_flag):\n",
    "    threshold = 0.8\n",
    "\n",
    "    x0, idx_HC_removed0 = removeHighCorrelatedColumns(x0, threshold)\n",
    "    x1, idx_HC_removed1 = removeHighCorrelatedColumns(x1, threshold)\n",
    "    x2, idx_HC_removed2 = removeHighCorrelatedColumns(x2, threshold)\n",
    "else:\n",
    "    idx_HC_removed0 = []\n",
    "    idx_HC_removed0 = []\n",
    "    idx_HC_removed0 = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25284301 0.48845637 0.99826244 ... 0.05036729 0.14712255 0.7379369 ]\n",
      "logistic loss:  206144.0091834263\n",
      "[0.17870741 0.54313832 0.99489064 ... 0.06757909 0.24649983 0.72179532]\n",
      "logistic loss:  179962.67376416817\n",
      "[0.12759058 0.58942464 0.98575404 ... 0.09051163 0.3706107  0.70565963]\n",
      "logistic loss:  155165.29019331522\n",
      "[0.09361042 0.62632905 0.96293375 ... 0.12032586 0.50006842 0.68932222]\n",
      "logistic loss:  132044.1101737867\n",
      "[0.07155176 0.65350667 0.91227951 ... 0.15763076 0.61433239 0.67246207]\n",
      "logistic loss:  110958.07197658595\n",
      "[0.05761697 0.67091502 0.81782346 ... 0.20174849 0.70233184 0.65461882]\n",
      "logistic loss:  92309.8779457699\n",
      "[0.04932898 0.67851069 0.67921184 ... 0.24990438 0.76317086 0.63511304]\n",
      "logistic loss:  76511.45860714294\n",
      "[0.04518304 0.67614856 0.52527021 ... 0.2969044  0.80101514 0.61303771]\n",
      "logistic loss:  63902.65321680614\n",
      "[0.04430203 0.66376458 0.39317211 ... 0.33601776 0.82081003 0.58748155]\n",
      "logistic loss:  54547.59357035903\n",
      "[0.04596679 0.64269883 0.29780071 ... 0.36169665 0.82760022 0.55764549]\n",
      "logistic loss:  48039.55116325912\n",
      "[0.04941995 0.33821876 0.6158613  ... 0.37209963 0.82592318 0.52374574]\n",
      "logistic loss:  43636.05881530697\n",
      "[0.05407749 0.3451912  0.58615731 ... 0.36935507 0.81873266 0.48897822]\n",
      "logistic loss:  40741.51331111562\n",
      "[0.05915954 0.35013281 0.55605163 ... 0.35765282 0.80877696 0.45374839]\n",
      "logistic loss:  38748.77252943882\n",
      "[0.06424102 0.353692   0.52718432 ... 0.34098337 0.79756446 0.42009412]\n",
      "logistic loss:  37319.39337530917\n",
      "[0.06907533 0.35623898 0.50046073 ... 0.32227353 0.78601272 0.38923069]\n",
      "logistic loss:  36257.43925171615\n",
      "[0.07337562 0.35767897 0.4758943  ... 0.30389582 0.77437741 0.36151516]\n",
      "logistic loss:  35449.008014754196\n",
      "[0.07731497 0.35870744 0.45398384 ... 0.28621326 0.7631719  0.33715069]\n",
      "logistic loss:  34809.83684261465\n",
      "[0.08090801 0.35941586 0.43456192 ... 0.26968966 0.75252154 0.31589737]\n",
      "logistic loss:  34294.32969425226\n",
      "[0.08418223 0.35985844 0.41737534 ... 0.25451108 0.74246264 0.29741134]\n",
      "logistic loss:  33871.75435544653\n",
      "[0.0871722  0.3600749  0.40215467 ... 0.24070079 0.73298843 0.28133092]\n",
      "logistic loss:  33520.56915500444\n",
      "[0.08991285 0.36009453 0.0896935  ... 0.10467267 0.72407132 0.26731594]\n",
      "logistic loss:  33432.56394100585\n",
      "[0.09225522 0.36077025 0.08692236 ... 0.1001902  0.71716249 0.25437049]\n",
      "logistic loss:  33193.84334003883\n",
      "[0.0944643  0.36099888 0.08455593 ... 0.09618409 0.71037838 0.24318853]\n",
      "logistic loss:  32988.861142415946\n",
      "[0.09654843 0.3608707  0.08251995 ... 0.09259443 0.70377226 0.23346737]\n",
      "logistic loss:  32811.40622392545\n",
      "[0.09851611 0.36045377 0.08075708 ... 0.0893696  0.6973797  0.22496512]\n",
      "logistic loss:  32656.61767979837\n",
      "[0.1003756  0.35980041 0.0792223  ... 0.08646492 0.69122375 0.21748721]\n",
      "logistic loss:  32520.633211155364\n",
      "[0.10213468 0.35895151 0.07787981 ... 0.08384166 0.6853185  0.2108761 ]\n",
      "logistic loss:  32400.34600098867\n",
      "[0.10380058 0.35793961 0.07670076 ... 0.0814662  0.67967162 0.20500336]\n",
      "logistic loss:  32293.25360635289\n",
      "[0.10537991 0.35679104 0.07566162 ... 0.07930928 0.67428606 0.19976358]\n",
      "logistic loss:  32197.357171004856\n",
      "[0.10687868 0.35552739 0.07474303 ... 0.07734546 0.66916135 0.1950697 ]\n",
      "logistic loss:  32111.05125601016\n",
      "[0.35416659 0.31259742 0.07392892 ... 0.85409833 0.11146302 0.15472018]\n",
      "logistic loss:  31848.168084260287\n",
      "[0.35218795 0.30824728 0.07275719 ... 0.85539633 0.10875613 0.14960912]\n",
      "logistic loss:  31772.86617620215\n",
      "[0.3501526  0.30407853 0.07175093 ... 0.85659077 0.10621248 0.14500457]\n",
      "logistic loss:  31704.984061095704\n",
      "[0.34807261 0.30008901 0.07088156 ... 0.85768686 0.10383161 0.14083441]\n",
      "logistic loss:  31643.33926328262\n",
      "[0.34595947 0.296274   0.07012653 ... 0.85869088 0.10160822 0.13704099]\n",
      "logistic loss:  31587.013129257208\n",
      "[0.34382362 0.29262718 0.06946789 ... 0.85960954 0.09953429 0.13357745]\n",
      "logistic loss:  31535.270508266847\n",
      "[0.34167418 0.2891412  0.06889115 ... 0.86044961 0.09760038 0.13040509]\n",
      "logistic loss:  31487.50968302742\n",
      "[0.33951893 0.28580819 0.06838456 ... 0.86121758 0.09579653 0.12749151]\n",
      "logistic loss:  31443.229784234456\n",
      "[0.33736437 0.28262002 0.06793849 ... 0.86191962 0.0941128  0.12480924]\n",
      "logistic loss:  31402.008627406773\n",
      "[0.33521585 0.27956863 0.06754494 ... 0.8625614  0.09253958 0.12233477]\n",
      "logistic loss:  31363.486985388394\n",
      "[0.99999123 0.9999894  1.         ... 0.99978207 0.99999994 0.99999518]\n",
      "logistic loss:  865160.3210982172\n",
      "[0.9785344  0.99105693 0.99999602 ... 0.77892862 0.99908712 0.99384315]\n",
      "logistic loss:  443456.38562012534\n",
      "[0.0730925  0.32626695 0.99036843 ... 0.01336912 0.30847557 0.34616115]\n",
      "logistic loss:  158410.73551838272\n",
      "[0.00323636 0.04392173 0.53778082 ... 0.00115932 0.01044829 0.04531634]\n",
      "logistic loss:  86083.50901357154\n",
      "[0.00419922 0.07533155 0.4247794  ... 0.00167781 0.02211888 0.05656218]\n",
      "logistic loss:  73442.8226753775\n",
      "[0.0045362  0.10150922 0.27472531 ... 0.00200457 0.03362794 0.05700692]\n",
      "logistic loss:  64313.65010635104\n",
      "[0.00527418 0.13479001 0.19055269 ... 0.00248418 0.05533994 0.05769484]\n",
      "logistic loss:  57568.49507392329\n",
      "[0.0088675  0.19918447 0.21966676 ... 0.00396765 0.10126332 0.0636034 ]\n",
      "logistic loss:  56185.324460084565\n",
      "[0.00633988 0.16520698 0.08569412 ... 0.00311054 0.06581016 0.04269743]\n",
      "logistic loss:  49278.1462859282\n",
      "[0.00821222 0.2092931  0.07099892 ... 0.00391958 0.11659974 0.04440072]\n",
      "logistic loss:  45611.19512507443\n",
      "[0.00957329 0.03544179 0.23550193 ... 0.00455523 0.16173524 0.04208272]\n",
      "logistic loss:  42738.32436009473\n",
      "[0.01112783 0.05076624 0.25783051 ... 0.00524683 0.21035771 0.04014413]\n",
      "logistic loss:  40688.60440209221\n",
      "[0.01278356 0.06834736 0.27561077 ... 0.00601392 0.25923418 0.03818529]\n",
      "logistic loss:  39088.4451850536\n",
      "[0.01459784 0.08751635 0.28985336 ... 0.0068571  0.30515609 0.03626973]\n",
      "logistic loss:  37797.08773509534\n",
      "[0.01650513 0.1069141  0.30038616 ... 0.0077465  0.34528853 0.03436467]\n",
      "logistic loss:  36727.1563937263\n",
      "[0.01852887 0.12598821 0.30831345 ... 0.00868517 0.38037113 0.03259131]\n",
      "logistic loss:  35823.641636728935\n",
      "[0.02065389 0.14408249 0.31413472 ... 0.00966205 0.41055956 0.03097446]\n",
      "logistic loss:  35048.833905682084\n",
      "[0.02289328 0.16098158 0.31853678 ... 0.01067701 0.43676126 0.02954468]\n",
      "logistic loss:  34376.03953507533\n",
      "[0.02525067 0.17653315 0.32196121 ... 0.01172631 0.45956236 0.02829728]\n",
      "logistic loss:  33786.50767044361\n",
      "[0.02771406 0.19059239 0.32465177 ... 0.01280074 0.47934493 0.02721521]\n",
      "logistic loss:  33266.40825212979\n",
      "[3.02716707e-02 2.03119413e-01 3.00443421e-02 ... 3.46270871e-04\n",
      " 4.96537629e-01 2.62864228e-02]\n",
      "logistic loss:  33007.80106623037\n",
      "[3.38069030e-02 2.21807826e-01 3.09846809e-02 ... 3.90396699e-04\n",
      " 5.25188778e-01 2.58573968e-02]\n",
      "logistic loss:  32601.435020951736\n",
      "[3.62546869e-02 2.29030524e-01 3.03546208e-02 ... 4.27347340e-04\n",
      " 5.33231372e-01 2.48188953e-02]\n",
      "logistic loss:  32210.174465882985\n",
      "[3.92666849e-02 2.39108129e-01 3.02993792e-02 ... 4.71771480e-04\n",
      " 5.48056927e-01 2.42304067e-02]\n",
      "logistic loss:  31867.30514356235\n",
      "[4.21187790e-02 2.45909692e-01 2.99654215e-02 ... 5.16902630e-04\n",
      " 5.57972947e-01 2.36725391e-02]\n",
      "logistic loss:  31554.87939973098\n",
      "[4.52667175e-02 2.53251938e-01 2.98288407e-02 ... 5.67531082e-04\n",
      " 5.68948745e-01 2.33399149e-02]\n",
      "logistic loss:  31278.177067043907\n",
      "[0.04844212 0.25936082 0.02962002 ... 0.00062158 0.57773702 0.0230865 ]\n",
      "logistic loss:  31029.064126463745\n",
      "[0.05171306 0.26496763 0.02942821 ... 0.00068002 0.5857813  0.02293735]\n",
      "logistic loss:  30805.093352190368\n",
      "[0.05500976 0.26981502 0.02921547 ... 0.00074247 0.59270516 0.02286147]\n",
      "logistic loss:  30602.812036500727\n",
      "[0.05833621 0.27413804 0.02900858 ... 0.00080927 0.59890116 0.02285865]\n",
      "logistic loss:  30420.458069270597\n",
      "[0.27791257 0.35716329 0.02880133 ... 0.96642812 0.17172488 0.02624008]\n",
      "logistic loss:  30398.20128533801\n",
      "[0.27677996 0.35752845 0.02772117 ... 0.96496594 0.16799519 0.02713658]\n",
      "logistic loss:  30242.608541078644\n",
      "[0.27882049 0.36031715 0.02716972 ... 0.96404991 0.16610195 0.0281923 ]\n",
      "logistic loss:  30104.014770151607\n",
      "[0.2791317  0.36194491 0.02654655 ... 0.96246723 0.16394322 0.02905628]\n",
      "logistic loss:  29974.82617242558\n",
      "[0.28051318 0.36438327 0.0261563  ... 0.96114523 0.16252959 0.02993838]\n",
      "logistic loss:  29858.91928849642\n",
      "[0.28037942 0.36582708 0.0257131  ... 0.9592828  0.16094687 0.03060195]\n",
      "logistic loss:  29750.26064796814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.28172236 0.36831955 0.02552052 ... 0.95801366 0.16022419 0.03131687]\n",
      "logistic loss:  29653.950167511648\n",
      "[0.28210091 0.37005596 0.0252953  ... 0.95654969 0.15934216 0.03189251]\n",
      "logistic loss:  29565.617299211466\n",
      "[0.28317487 0.37218173 0.02519842 ... 0.95547213 0.15882768 0.03247863]\n",
      "logistic loss:  29486.632187582953\n",
      "[0.28359028 0.37371964 0.02507555 ... 0.95427381 0.15813669 0.03296086]\n",
      "logistic loss:  29414.029764332514\n",
      "[0.25284301 0.48845637 0.99826244 ... 0.05036729 0.14712255 0.7379369 ]\n",
      "logistic loss:  206144.0091834263\n",
      "[0.17870744 0.54313832 0.99489063 ... 0.06757913 0.24649989 0.72179527]\n",
      "logistic loss:  179962.63692648825\n",
      "[0.12759064 0.58942463 0.985754   ... 0.09051172 0.37061083 0.70565955]\n",
      "logistic loss:  155165.2221761832\n",
      "[0.0936105  0.62632902 0.96293364 ... 0.12032602 0.50006857 0.68932209]\n",
      "logistic loss:  132044.0188158928\n",
      "[0.07155186 0.6535066  0.91227922 ... 0.157631   0.61433251 0.6724619 ]\n",
      "logistic loss:  110957.96471019152\n",
      "[0.05761708 0.6709149  0.81782288 ... 0.20174882 0.70233189 0.65461861]\n",
      "logistic loss:  92309.76341323652\n",
      "[0.0493291  0.67851052 0.679211   ... 0.24990478 0.76317083 0.63511278]\n",
      "logistic loss:  76511.34611805623\n",
      "[0.04518319 0.67614831 0.52526934 ... 0.29690481 0.80101502 0.61303739]\n",
      "logistic loss:  63902.55178331929\n",
      "[0.04430221 0.66376425 0.39317142 ... 0.33601811 0.8208098  0.58748117]\n",
      "logistic loss:  54547.50950943018\n",
      "[0.04596701 0.64269842 0.29780027 ... 0.36169688 0.8275999  0.55764503]\n",
      "logistic loss:  48039.48567126924\n",
      "[0.0494202  0.33821921 0.61586084 ... 0.37209972 0.82592278 0.52374523]\n",
      "logistic loss:  43636.009714817614\n",
      "[0.05407778 0.34519167 0.58615682 ... 0.36935503 0.81873219 0.48897768]\n",
      "logistic loss:  40741.476180462465\n",
      "[0.05915987 0.35013329 0.55605114 ... 0.35765268 0.80877644 0.45374786]\n",
      "logistic loss:  38748.743963073706\n",
      "[0.06424137 0.35369249 0.52718386 ... 0.34098318 0.79756389 0.42009361]\n",
      "logistic loss:  37319.37089120828\n",
      "[0.0690757  0.35623949 0.50046031 ... 0.32227331 0.78601211 0.38923024]\n",
      "logistic loss:  36257.42137210538\n",
      "[0.07337599 0.35767949 0.47589393 ... 0.3038956  0.77437677 0.36151476]\n",
      "logistic loss:  35448.9934956862\n",
      "[0.07731536 0.35870797 0.45398354 ... 0.28621306 0.76317124 0.33715037]\n",
      "logistic loss:  34809.82494267776\n",
      "[0.08090841 0.3594164  0.43456167 ... 0.26968948 0.75252085 0.31589711]\n",
      "logistic loss:  34294.31991805424\n",
      "[0.08418264 0.35985899 0.41737516 ... 0.25451093 0.74246194 0.29741115]\n",
      "logistic loss:  33871.74634319461\n",
      "[0.08717261 0.36007546 0.40215453 ... 0.24070067 0.73298772 0.28133079]\n",
      "logistic loss:  33520.56263779359\n",
      "[0.08991326 0.3600951  0.08969376 ... 0.10467293 0.7240706  0.26731586]\n",
      "logistic loss:  33432.55849540238\n",
      "[0.09225563 0.36077083 0.08692264 ... 0.10019047 0.71716175 0.25437046]\n",
      "logistic loss:  33193.83901787349\n",
      "[0.09446471 0.36099948 0.08455621 ... 0.09618437 0.71037764 0.24318856]\n",
      "logistic loss:  32988.85781916262\n",
      "[0.09654884 0.3608713  0.08252024 ... 0.09259473 0.70377152 0.23346744]\n",
      "logistic loss:  32811.40379600954\n",
      "[0.09851652 0.36045438 0.08075738 ... 0.0893699  0.69737895 0.22496523]\n",
      "logistic loss:  32656.616059872023\n",
      "[0.10037601 0.35980103 0.07922261 ... 0.08646524 0.69122299 0.21748736]\n",
      "logistic loss:  32520.632324667247\n",
      "[0.10213509 0.35895214 0.07788013 ... 0.08384199 0.68531775 0.21087629]\n",
      "logistic loss:  32400.34578401182\n",
      "[0.10380099 0.35794026 0.07670108 ... 0.08146654 0.67967087 0.20500358]\n",
      "logistic loss:  32293.25400426819\n",
      "[0.10538031 0.3567917  0.07566195 ... 0.07930963 0.67428531 0.19976384]\n",
      "logistic loss:  32197.358136891493\n",
      "[0.10687908 0.35552806 0.07474337 ... 0.07734582 0.6691606  0.19506999]\n",
      "logistic loss:  32111.05274863907\n",
      "[0.35416728 0.31259778 0.07392927 ... 0.85409791 0.11146315 0.15472037]\n",
      "logistic loss:  31848.170363964186\n",
      "[0.35218866 0.30824768 0.07275754 ... 0.85539591 0.10875628 0.14960934]\n",
      "logistic loss:  31772.868881188802\n",
      "[0.35015332 0.30407896 0.07175129 ... 0.85659034 0.10621264 0.1450048 ]\n",
      "logistic loss:  31704.987163395985\n",
      "[0.34807334 0.30008946 0.07088192 ... 0.85768642 0.10383177 0.14083466]\n",
      "logistic loss:  31643.34273763581\n",
      "[0.34596023 0.29627449 0.0701269  ... 0.85869043 0.1016084  0.13704126]\n",
      "logistic loss:  31587.016953005885\n",
      "[0.34382439 0.2926277  0.06946825 ... 0.85960909 0.09953448 0.13357774]\n",
      "logistic loss:  31535.274661111966\n",
      "[0.34167497 0.28914175 0.06889152 ... 0.86044915 0.09760058 0.1304054 ]\n",
      "logistic loss:  31487.51414675965\n",
      "[0.33951974 0.28580876 0.06838494 ... 0.86121712 0.09579673 0.12749183]\n",
      "logistic loss:  31443.234542484548\n",
      "[0.3373652  0.28262063 0.06793887 ... 0.86191914 0.09411301 0.12480958]\n",
      "logistic loss:  31402.01366542743\n",
      "[0.3352167  0.27956926 0.06754533 ... 0.86256092 0.09253979 0.12233513]\n",
      "logistic loss:  31363.49228986742\n",
      "[0.99999123 0.9999894  1.         ... 0.99978207 0.99999994 0.99999518]\n",
      "logistic loss:  865160.3210982172\n",
      "[0.97853435 0.99105691 0.99999602 ... 0.77892833 0.99908712 0.99384313]\n",
      "logistic loss:  443456.19859767234\n",
      "[0.07309233 0.32626637 0.99036837 ... 0.0133691  0.30847473 0.34616053]\n",
      "logistic loss:  158410.558867711\n",
      "[0.00323636 0.04392173 0.53777981 ... 0.00115932 0.01044829 0.04531633]\n",
      "logistic loss:  86083.4572460274\n",
      "[0.00419924 0.07533172 0.42477916 ... 0.00167782 0.02211897 0.05656229]\n",
      "logistic loss:  73442.76066418418\n",
      "[0.00453622 0.10150946 0.27472513 ... 0.00200459 0.03362809 0.05700705]\n",
      "logistic loss:  64313.58430662006\n",
      "[0.00527421 0.13479034 0.19055265 ... 0.0024842  0.05534021 0.05769499]\n",
      "logistic loss:  57568.428022381646\n",
      "[0.00886757 0.19918493 0.21966681 ... 0.00396769 0.1012638  0.06360358]\n",
      "logistic loss:  56185.25831633646\n",
      "[0.00633992 0.16520729 0.08569411 ... 0.00311057 0.06581042 0.04269755]\n",
      "logistic loss:  49278.079262037296\n",
      "[0.00821229 0.2092936  0.07099904 ... 0.00391962 0.11660036 0.04440089]\n",
      "logistic loss:  45611.12964676057\n",
      "[0.00957337 0.03544211 0.23550239 ... 0.00455528 0.16173598 0.04208289]\n",
      "logistic loss:  42738.261337504344\n",
      "[0.01112793 0.05076667 0.25783096 ... 0.00524689 0.21035858 0.04014431]\n",
      "logistic loss:  40688.543790047086\n",
      "[0.01278369 0.06834792 0.27561121 ... 0.006014   0.25923515 0.03818548]\n",
      "logistic loss:  39088.386618798846\n",
      "[0.01459798 0.08751701 0.28985377 ... 0.00685719 0.30515706 0.03626992]\n",
      "logistic loss:  37797.03094394051\n",
      "[0.0165053  0.10691485 0.30038653 ... 0.0077466  0.34528947 0.03436487]\n",
      "logistic loss:  36727.101234643196\n",
      "[0.01852906 0.12598903 0.30831379 ... 0.00868529 0.380372   0.03259152]\n",
      "logistic loss:  35823.588001494165\n",
      "[0.02065411 0.14408335 0.31413504 ... 0.00966218 0.41056036 0.03097468]\n",
      "logistic loss:  35048.781739001795\n",
      "[0.02289352 0.16098247 0.31853707 ... 0.01067716 0.43676196 0.0295449 ]\n",
      "logistic loss:  34375.98884765814\n",
      "[0.02525095 0.17653405 0.32196148 ... 0.01172648 0.45956297 0.02829751]\n",
      "logistic loss:  33786.458500750436\n",
      "[0.02771437 0.19059329 0.32465203 ... 0.01280093 0.47934545 0.02721545]\n",
      "logistic loss:  33266.36065323171\n",
      "[3.02720021e-02 2.03120299e-01 3.00445896e-02 ... 3.46281157e-04\n",
      " 4.96538058e-01 2.62866674e-02]\n",
      "logistic loss:  33007.754283427785\n",
      "[3.38072715e-02 2.21808719e-01 3.09849489e-02 ... 3.90408661e-04\n",
      " 5.25189121e-01 2.58576533e-02]\n",
      "logistic loss:  32601.389866891765\n",
      "[3.62550758e-02 2.29031358e-01 3.03548904e-02 ... 4.27360776e-04\n",
      " 5.33231577e-01 2.48191547e-02]\n",
      "logistic loss:  32210.130832445728\n",
      "[3.92671036e-02 2.39108953e-01 3.02996609e-02 ... 4.71786716e-04\n",
      " 5.48057079e-01 2.42306761e-02]\n",
      "logistic loss:  31867.26335021809\n",
      "[4.21192203e-02 2.45910464e-01 2.99657078e-02 ... 5.16919692e-04\n",
      " 5.57972984e-01 2.36728163e-02]\n",
      "logistic loss:  31554.839305125122\n",
      "[4.52671895e-02 2.53252723e-01 2.98291393e-02 ... 5.67550285e-04\n",
      " 5.68948747e-01 2.33402042e-02]\n",
      "logistic loss:  31278.13886453676\n",
      "[0.04844262 0.25936156 0.02962032 ... 0.0006216  0.57773691 0.0230868 ]\n",
      "logistic loss:  31029.027589323574\n",
      "[0.05171358 0.26496837 0.02942852 ... 0.00068004 0.58578113 0.02293766]\n",
      "logistic loss:  30805.058411298814\n",
      "[0.05501029 0.26981573 0.02921579 ... 0.00074249 0.5927049  0.02286179]\n",
      "logistic loss:  30602.77868592159\n",
      "[0.05833676 0.27413874 0.02900891 ... 0.0008093  0.59890083 0.02285898]\n",
      "logistic loss:  30420.42635213255\n",
      "[0.27791326 0.35716341 0.02880166 ... 0.96642769 0.17172482 0.02624047]\n",
      "logistic loss:  30398.170378949355\n",
      "[0.2767806  0.35752853 0.02772149 ... 0.9649655  0.16799513 0.02713698]\n",
      "logistic loss:  30242.579109133825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.27882116 0.36031722 0.02717005 ... 0.96404947 0.1661019  0.02819272]\n",
      "logistic loss:  30103.986105248572\n",
      "[0.27913234 0.36194494 0.02654688 ... 0.96246677 0.16394317 0.0290567 ]\n",
      "logistic loss:  29974.799283528395\n",
      "[0.28051383 0.36438328 0.02615663 ... 0.96114476 0.16252954 0.0299388 ]\n",
      "logistic loss:  29858.89382353335\n",
      "[0.28038004 0.36582704 0.02571343 ... 0.95928231 0.16094682 0.03060238]\n",
      "logistic loss:  29750.236316940798\n",
      "[0.28172306 0.36831953 0.02552087 ... 0.95801319 0.16022417 0.03131731]\n",
      "logistic loss:  29653.92719963035\n",
      "[0.28210156 0.37005586 0.02529564 ... 0.9565492  0.15934212 0.03189295]\n",
      "logistic loss:  29565.595450610264\n",
      "[0.28317556 0.37218163 0.02519877 ... 0.95547165 0.15882765 0.03247908]\n",
      "logistic loss:  29486.61145478112\n",
      "[0.28359094 0.37371948 0.0250759  ... 0.95427331 0.15813665 0.03296131]\n",
      "logistic loss:  29414.01002555431\n",
      "max acc =  0.8159180078469053\n",
      "[0.9000567  0.00468867 0.99997016 ... 0.99941083 0.66834536 0.03470827]\n",
      "logistic loss:  148274.98834617162\n",
      "[0.90017067 0.00740037 0.99992594 ... 0.9987109  0.68091231 0.040744  ]\n",
      "logistic loss:  137139.8471635768\n",
      "[0.89912788 0.01148744 0.99981968 ... 0.99724259 0.69235588 0.04756665]\n",
      "logistic loss:  126309.78810899015\n",
      "[0.89685492 0.01750137 0.99957028 ... 0.99425351 0.70256034 0.05520134]\n",
      "logistic loss:  115856.43428220903\n",
      "[0.89324578 0.02610862 0.99900052 ... 0.9883831  0.71140242 0.0636509 ]\n",
      "logistic loss:  105845.81648646524\n",
      "[0.88816089 0.0380394  0.99773863 ... 0.97734969 0.7187522  0.07288968]\n",
      "logistic loss:  96352.71660007397\n",
      "[0.8814288  0.05397939 0.99504349 ... 0.95772176 0.72447566 0.08285706]\n",
      "logistic loss:  87460.10126729362\n",
      "[0.87285081 0.07439985 0.98953194 ... 0.9251516  0.72844012 0.09345058]\n",
      "logistic loss:  79236.31740806942\n",
      "[0.86220905 0.09935027 0.97884762 ... 0.87562605 0.73052137 0.10451934]\n",
      "logistic loss:  71745.65477431325\n",
      "[0.84927824 0.12827321 0.95948435 ... 0.807882   0.73061203 0.11585804]\n",
      "logistic loss:  65054.474635004546\n",
      "[0.83384449 0.428157   0.87796894 ... 0.72574747 0.728636   0.12720275]\n",
      "logistic loss:  59138.11771495047\n",
      "[0.81649635 0.30881477 0.85032773 ... 0.63600945 0.72373726 0.13798933]\n",
      "logistic loss:  54156.71418888272\n",
      "[0.79644227 0.22567411 0.81998893 ... 0.5506578  0.71685547 0.14805351]\n",
      "logistic loss:  50007.74919340413\n",
      "[0.7738378  0.17184756 0.78820684 ... 0.47737471 0.70812391 0.15706169]\n",
      "logistic loss:  46636.56753269837\n",
      "[0.7490703  0.13821923 0.75652228 ... 0.4193164  0.69778413 0.16474792]\n",
      "logistic loss:  43952.444014371285\n",
      "[0.72280406 0.11758717 0.72641826 ... 0.37588824 0.68615253 0.17098503]\n",
      "logistic loss:  41840.85844090409\n",
      "[0.69594233 0.10520877 0.69892777 ... 0.34457512 0.6735603  0.17583387]\n",
      "logistic loss:  40181.32047923879\n",
      "[0.66949757 0.09804629 0.6744568  ... 0.32231164 0.66031599 0.17954947]\n",
      "logistic loss:  38864.63620011454\n",
      "[0.64436925 0.09419081 0.6529145  ... 0.30637926 0.64666795 0.18247672]\n",
      "logistic loss:  37805.18638798673\n",
      "[0.62121079 0.09243962 0.63395428 ... 0.29470013 0.63280545 0.18494493]\n",
      "logistic loss:  36941.01550448443\n",
      "[0.09202428 0.35588085 0.4394604  ... 0.5197665  0.45668527 0.34183638]\n",
      "logistic loss:  36555.19946149549\n",
      "[0.09364937 0.36611701 0.42752898 ... 0.50621385 0.46645318 0.3306062 ]\n",
      "logistic loss:  35931.10086981021\n",
      "[0.0956282  0.37669604 0.41717392 ... 0.49447112 0.47457123 0.31937861]\n",
      "logistic loss:  35407.29609159992\n",
      "[0.09778614 0.38757382 0.40811686 ... 0.48439397 0.48142798 0.30832916]\n",
      "logistic loss:  34965.33803747217\n",
      "[0.10000052 0.39867445 0.40017015 ... 0.47580531 0.48732617 0.29759269]\n",
      "logistic loss:  34590.46067965889\n",
      "[0.10218645 0.40990793 0.39319836 ... 0.46851924 0.49249988 0.28726768]\n",
      "logistic loss:  34270.80798890797\n",
      "[0.10428696 0.42118148 0.38709547 ... 0.46235576 0.49712865 0.27742149]\n",
      "logistic loss:  33996.83708647674\n",
      "[0.10626577 0.4324066  0.38177224 ... 0.45714879 0.50134887 0.26809563]\n",
      "logistic loss:  33760.84712935989\n",
      "[0.10810183 0.44350298 0.37714973 ... 0.45274986 0.50526293 0.25931099]\n",
      "logistic loss:  33556.60429835043\n",
      "[0.10978517 0.45440062 0.37315616 ... 0.44902909 0.50894666 0.25107247]\n",
      "logistic loss:  33379.04287860339\n",
      "[0.49883909 0.11131368 0.46504058 ... 0.24750077 0.50235137 0.21855416]\n",
      "logistic loss:  33024.1953966106\n",
      "[0.49506276 0.11169623 0.47599071 ... 0.24568737 0.49128612 0.22070649]\n",
      "logistic loss:  32892.08567796374\n",
      "[0.49180914 0.11204626 0.48638289 ... 0.2441928  0.48097087 0.22281925]\n",
      "logistic loss:  32775.95966079052\n",
      "[0.48904192 0.1123512  0.49628162 ... 0.24290641 0.4713533  0.22490943]\n",
      "logistic loss:  32673.517451180014\n",
      "[0.48670834 0.1126074  0.50571654 ... 0.24176998 0.46238424 0.22697842]\n",
      "logistic loss:  32582.853203661398\n",
      "[0.48475252 0.1128158  0.51470234 ... 0.24075154 0.45401763 0.22902087]\n",
      "logistic loss:  32502.368631456673\n",
      "[0.48312158 0.11297958 0.52324845 ... 0.23983227 0.44621037 0.23102918]\n",
      "logistic loss:  32430.71383768586\n",
      "[0.48176803 0.1131029  0.53136359 ... 0.23899992 0.43892224 0.23299556]\n",
      "logistic loss:  32366.742499282787\n",
      "[0.48065034 0.11319021 0.53905755 ... 0.23824558 0.43211588 0.23491305]\n",
      "logistic loss:  32309.47652918068\n",
      "[0.47973274 0.11324589 0.54634179 ... 0.23756216 0.42575659 0.2367758 ]\n",
      "logistic loss:  32258.077758703083\n",
      "[0.99999994 0.99998938 1.         ... 1.         0.99994012 0.99543545]\n",
      "logistic loss:  628182.869446989\n",
      "[0.99997304 0.9935894  1.         ... 1.         0.99755298 0.86112309]\n",
      "logistic loss:  409230.802875233\n",
      "[0.99237064 0.29242879 1.         ... 0.99999629 0.9317616  0.20236919]\n",
      "logistic loss:  221232.03934348776\n",
      "[0.75481076 0.0074571  0.99999994 ... 0.99682788 0.60772119 0.04078207]\n",
      "logistic loss:  117705.64444786147\n",
      "[0.47068862 0.00143476 0.99987805 ... 0.8635155  0.40424878 0.02685741]\n",
      "logistic loss:  84123.09131367132\n",
      "[0.46479493 0.00130937 0.98409488 ... 0.53984759 0.41830838 0.03292942]\n",
      "logistic loss:  69058.53624555832\n",
      "[0.54934965 0.00256793 0.9625898  ... 0.46541765 0.51231013 0.05032235]\n",
      "logistic loss:  63359.38962812565\n",
      "[0.60536103 0.00532085 0.98488137 ... 0.45248087 0.59436598 0.07211625]\n",
      "logistic loss:  59481.75371043647\n",
      "[0.59627531 0.00695975 0.95418673 ... 0.30223961 0.62381521 0.08521397]\n",
      "logistic loss:  55689.39598651325\n",
      "[0.61963961 0.01304541 0.989211   ... 0.31236176 0.67958719 0.10904146]\n",
      "logistic loss:  53135.21861821775\n",
      "[5.72174549e-01 8.33060171e-04 9.13001211e-01 ... 1.59572836e-01\n",
      " 6.78533903e-01 1.12462443e-01]\n",
      "logistic loss:  50503.663703128725\n",
      "[0.61584957 0.00225556 0.93880875 ... 0.24268471 0.73984765 0.14568679]\n",
      "logistic loss:  49720.07219866142\n",
      "[5.21121811e-01 6.90317151e-04 8.91578470e-01 ... 7.58800883e-02\n",
      " 7.03099092e-01 1.28855238e-01]\n",
      "logistic loss:  47756.122834745795\n",
      "[0.60908085 0.00382687 0.94156757 ... 0.2022124  0.78440171 0.17982305]\n",
      "logistic loss:  48007.46396860329\n",
      "[4.74003176e-01 6.12638901e-04 8.80526939e-01 ... 4.46943290e-02\n",
      " 7.25468560e-01 1.43488481e-01]\n",
      "logistic loss:  44729.59383196346\n",
      "[0.58118601 0.00457176 0.9393268  ... 0.14994454 0.80700013 0.20339166]\n",
      "logistic loss:  45915.26396947443\n",
      "[4.36342053e-01 6.52890674e-04 8.72393578e-01 ... 3.07156191e-02\n",
      " 7.43573869e-01 1.57390008e-01]\n",
      "logistic loss:  41907.33358174836\n",
      "[0.55117541 0.00555885 0.93557586 ... 0.11407101 0.82055309 0.22204799]\n",
      "logistic loss:  44109.37783663398\n",
      "[4.02870813e-01 7.64372878e-04 8.63464501e-01 ... 2.26820682e-02\n",
      " 7.54612296e-01 1.69025391e-01]\n",
      "logistic loss:  39566.30634336837\n",
      "[0.52367785 0.0071681  0.93117067 ... 0.09059207 0.82864247 0.23775637]\n",
      "logistic loss:  42652.47598581484\n",
      "[0.00091207 0.09562392 0.81623219 ... 0.15744462 0.2018422  0.55798567]\n",
      "logistic loss:  38128.80606721269\n",
      "[0.01027195 0.25593118 0.99895501 ... 0.25874533 0.47890196 0.65689948]\n",
      "logistic loss:  41942.34073398692\n",
      "[0.00132454 0.12901249 0.83503313 ... 0.15173852 0.25880829 0.54109452]\n",
      "logistic loss:  36361.702016425406\n",
      "[0.01509749 0.31971929 0.99891439 ... 0.25390427 0.55475162 0.64200444]\n",
      "logistic loss:  40738.49281537674\n",
      "[0.00184286 0.1652916  0.83167352 ... 0.14874194 0.31494742 0.52197511]\n",
      "logistic loss:  35184.48643695199\n",
      "[0.02190117 0.38791173 0.99892883 ... 0.25444567 0.62419214 0.62705007]\n",
      "logistic loss:  39990.71839582382\n",
      "[0.0023717  0.20348926 0.82776853 ... 0.14661276 0.36613645 0.49944253]\n",
      "logistic loss:  34192.83201455705\n",
      "[0.02908301 0.45031968 0.99888689 ... 0.25589234 0.67793739 0.60910102]\n",
      "logistic loss:  39291.70499505421\n",
      "[0.00290237 0.24226451 0.81953863 ... 0.1460739  0.41210166 0.47640298]\n",
      "logistic loss:  33439.4663006981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03671667 0.50791503 0.99885446 ... 0.25950361 0.72132452 0.59066407]\n",
      "logistic loss:  38763.069462354455\n",
      "[0.28491938 0.00336545 0.28019353 ... 0.00873049 0.73809802 0.22332773]\n",
      "logistic loss:  32403.26225486893\n",
      "[0.42508003 0.03958578 0.55647533 ... 0.04540578 0.81877048 0.31512743]\n",
      "logistic loss:  38064.13973801965\n",
      "[0.27106383 0.00315554 0.31486007 ... 0.00795384 0.72546372 0.22766045]\n",
      "logistic loss:  31843.2471389267\n",
      "[0.41298762 0.03927964 0.59282054 ... 0.04101681 0.81023581 0.32162583]\n",
      "logistic loss:  37205.806246434586\n",
      "[0.26498338 0.00343832 0.35070598 ... 0.00747544 0.71634473 0.23427373]\n",
      "logistic loss:  31650.196250782697\n",
      "[0.41047408 0.04650291 0.64067998 ... 0.0422768  0.80593282 0.33280026]\n",
      "logistic loss:  37561.607068818616\n",
      "[0.25338657 0.00328105 0.38059352 ... 0.00707208 0.7024182  0.23712524]\n",
      "logistic loss:  31155.502716051255\n",
      "[0.39778264 0.0439902  0.65715499 ... 0.03707397 0.79471869 0.3352779 ]\n",
      "logistic loss:  36187.21578635444\n",
      "[0.25360519 0.00390983 0.41225022 ... 0.00689423 0.6958543  0.24476595]\n",
      "logistic loss:  31372.957919817236\n",
      "[0.40509182 0.06018633 0.71046273 ... 0.04447065 0.79496588 0.3510966 ]\n",
      "logistic loss:  37979.303616848105\n",
      "[0.9000567  0.00468867 0.99997016 ... 0.99941083 0.66834536 0.03470827]\n",
      "logistic loss:  148274.98834617162\n",
      "[0.90017063 0.00740037 0.99992594 ... 0.9987109  0.68091227 0.04074403]\n",
      "logistic loss:  137139.8216895363\n",
      "[0.8991278  0.01148746 0.99981968 ... 0.99724259 0.69235582 0.04756671]\n",
      "logistic loss:  126309.73768234727\n",
      "[0.8968548  0.01750142 0.99957028 ... 0.99425349 0.70256024 0.05520144]\n",
      "logistic loss:  115856.36132156159\n",
      "[0.89324561 0.02610872 0.99900051 ... 0.98838305 0.71140228 0.06365105]\n",
      "logistic loss:  105845.72752769249\n",
      "[0.88816067 0.03803956 0.99773861 ... 0.97734957 0.71875203 0.07288988]\n",
      "logistic loss:  96352.61175134739\n",
      "[0.88142852 0.05397964 0.99504344 ... 0.9577215  0.72447544 0.08285731]\n",
      "logistic loss:  87459.98469074914\n",
      "[0.87285046 0.07440021 0.98953183 ... 0.92515114 0.72843986 0.0934509 ]\n",
      "logistic loss:  79236.1928415444\n",
      "[0.86220863 0.09935076 0.9788474  ... 0.87562531 0.73052105 0.10451972]\n",
      "logistic loss:  71745.52556472577\n",
      "[0.84927773 0.12827384 0.95948392 ... 0.80788095 0.73061165 0.11585849]\n",
      "logistic loss:  65054.345301682755\n",
      "[0.83384389 0.4281556  0.87796828 ... 0.72574619 0.72863556 0.12720326]\n",
      "logistic loss:  59137.99215950521\n",
      "[0.81649564 0.30881376 0.85032693 ... 0.63600808 0.72373674 0.1379899 ]\n",
      "logistic loss:  54156.59522480212\n",
      "[0.79644147 0.2256735  0.81998801 ... 0.55065653 0.71685489 0.14805413]\n",
      "logistic loss:  50007.639467051005\n",
      "[0.77383689 0.17184725 0.78820582 ... 0.47737365 0.70812325 0.15706234]\n",
      "logistic loss:  46636.46858877043\n",
      "[0.7490693  0.13821914 0.75652122 ... 0.41931562 0.69778339 0.1647486 ]\n",
      "logistic loss:  43952.35635438674\n",
      "[0.72280298 0.11758724 0.7264172  ... 0.37588773 0.68615173 0.17098572]\n",
      "logistic loss:  41840.78144928064\n",
      "[0.69594121 0.10520894 0.69892674 ... 0.34457484 0.67355943 0.17583457]\n",
      "logistic loss:  40181.2528873648\n",
      "[0.66949644 0.09804654 0.67445582 ... 0.32231155 0.66031507 0.17955018]\n",
      "logistic loss:  38864.57659410359\n",
      "[0.64436814 0.09419111 0.65291359 ... 0.30637931 0.64666699 0.18247744]\n",
      "logistic loss:  37805.13353617901\n",
      "[0.62120974 0.09243996 0.63395343 ... 0.29470028 0.63280446 0.18494567]\n",
      "logistic loss:  36940.968430732064\n",
      "[0.09202465 0.35588162 0.43946031 ... 0.51976599 0.45668561 0.3418362 ]\n",
      "logistic loss:  36555.15605616464\n",
      "[0.09364975 0.3661178  0.42752902 ... 0.50621337 0.46645345 0.33060601]\n",
      "logistic loss:  35931.06193735997\n",
      "[0.0956286  0.37669685 0.41717405 ... 0.49447069 0.47457144 0.31937843]\n",
      "logistic loss:  35407.26112520374\n",
      "[0.09778654 0.38757464 0.40811707 ... 0.48439359 0.48142815 0.308329  ]\n",
      "logistic loss:  34965.30659076602\n",
      "[0.10000092 0.39867527 0.40017043 ... 0.47580498 0.48732629 0.29759254]\n",
      "logistic loss:  34590.43235949203\n",
      "[0.10218685 0.40990874 0.3931987  ... 0.46851896 0.49249997 0.28726757]\n",
      "logistic loss:  34270.78245008315\n",
      "[0.10428735 0.42118229 0.38709587 ... 0.46235552 0.49712871 0.2774214 ]\n",
      "logistic loss:  33996.81402691886\n",
      "[0.10626615 0.43240739 0.38177269 ... 0.45714858 0.50134891 0.26809557]\n",
      "logistic loss:  33760.82628530214\n",
      "[0.10810219 0.44350375 0.37715023 ... 0.45274968 0.50526294 0.25931097]\n",
      "logistic loss:  33556.58543958393\n",
      "[0.10978552 0.45440136 0.3731567  ... 0.44902894 0.50894665 0.25107248]\n",
      "logistic loss:  33379.02580397\n",
      "[0.49883877 0.11131402 0.46504127 ... 0.24750123 0.50235044 0.21855512]\n",
      "logistic loss:  33024.18056710182\n",
      "[0.49506247 0.11169654 0.47599135 ... 0.24568785 0.49128523 0.22070745]\n",
      "logistic loss:  32892.072253339546\n",
      "[0.49180887 0.11204656 0.48638349 ... 0.24419329 0.48097001 0.22282022]\n",
      "logistic loss:  32775.94750984476\n",
      "[0.48904168 0.11235148 0.49628216 ... 0.24290692 0.47135247 0.2249104 ]\n",
      "logistic loss:  32673.50645733529\n",
      "[0.48670812 0.11260766 0.50571703 ... 0.2417705  0.46238345 0.22697939]\n",
      "logistic loss:  32582.8432627441\n",
      "[0.48475231 0.11281604 0.51470276 ... 0.24075207 0.45401688 0.22902184]\n",
      "logistic loss:  32502.35964997353\n",
      "[0.48312138 0.11297981 0.52324881 ... 0.23983281 0.44620965 0.23103015]\n",
      "logistic loss:  32430.7057314336\n",
      "[0.48176784 0.11310311 0.53136389 ... 0.23900046 0.43892156 0.23299653]\n",
      "logistic loss:  32366.735192200744\n",
      "[0.48065015 0.11319041 0.53905779 ... 0.23824614 0.43211523 0.23491401]\n",
      "logistic loss:  32309.469952392377\n",
      "[0.47973257 0.11324608 0.54634197 ... 0.23756273 0.42575598 0.23677676]\n",
      "logistic loss:  32258.0718497095\n",
      "[0.99999994 0.99998938 1.         ... 1.         0.99994012 0.99543545]\n",
      "logistic loss:  628182.869446989\n",
      "[0.99997303 0.99358938 1.         ... 1.         0.99755298 0.86112296]\n",
      "logistic loss:  409230.701375258\n",
      "[0.9923706  0.29242817 1.         ... 0.99999629 0.93176142 0.20236899]\n",
      "logistic loss:  221231.86902246557\n",
      "[0.7548099  0.00745709 0.99999994 ... 0.99682785 0.60772057 0.04078207]\n",
      "logistic loss:  117705.50923132521\n",
      "[0.47068817 0.00143476 0.99987805 ... 0.8635146  0.4042486  0.02685746]\n",
      "logistic loss:  84122.9975190198\n",
      "[0.46479492 0.00130938 0.98409464 ... 0.53984669 0.41830861 0.03292954]\n",
      "logistic loss:  69058.458398633\n",
      "[0.54934986 0.00256796 0.96259    ... 0.46541797 0.51231055 0.05032261]\n",
      "logistic loss:  63359.31370980852\n",
      "[0.60536071 0.00532089 0.98488114 ... 0.45247973 0.59436594 0.07211654]\n",
      "logistic loss:  59481.66454138086\n",
      "[0.59627526 0.00695983 0.95418703 ... 0.30223993 0.6238154  0.08521442]\n",
      "logistic loss:  55689.30732743349\n",
      "[0.619639   0.01304553 0.98921081 ... 0.31236076 0.67958692 0.10904189]\n",
      "logistic loss:  53135.11602984909\n",
      "[5.72174281e-01 8.33074886e-04 9.13000867e-01 ... 1.59573088e-01\n",
      " 6.78533852e-01 1.12463029e-01]\n",
      "logistic loss:  50503.562265684224\n",
      "[0.61584892 0.00225559 0.93880835 ... 0.24268439 0.7398473  0.14568742]\n",
      "logistic loss:  49719.975481334026\n",
      "[5.21121085e-01 6.90327481e-04 8.91577745e-01 ... 7.58800000e-02\n",
      " 7.03098642e-01 1.28855811e-01]\n",
      "logistic loss:  47756.04553238812\n",
      "[0.60908051 0.00382695 0.94156728 ... 0.20221307 0.78440151 0.17982398]\n",
      "logistic loss:  48007.40459441612\n",
      "[4.74002147e-01 6.12645657e-04 8.80526081e-01 ... 4.46942997e-02\n",
      " 7.25467850e-01 1.43489061e-01]\n",
      "logistic loss:  44729.51486799751\n",
      "[0.58118556 0.00457185 0.93932646 ... 0.1499452  0.80699977 0.20339269]\n",
      "logistic loss:  45915.20982567068\n",
      "[4.36340987e-01 6.52897986e-04 8.72392626e-01 ... 3.07156580e-02\n",
      " 7.43572996e-01 1.57390651e-01]\n",
      "logistic loss:  41907.25109843914\n",
      "[0.55117492 0.00555896 0.93557545 ... 0.11407168 0.82055259 0.22204911]\n",
      "logistic loss:  44109.32672736353\n",
      "[4.02869745e-01 7.64381449e-04 8.63463403e-01 ... 2.26821303e-02\n",
      " 7.54611234e-01 1.69026083e-01]\n",
      "logistic loss:  39566.22794175062\n",
      "[0.52367742 0.00716825 0.9311702  ... 0.09059279 0.82864186 0.23775759]\n",
      "logistic loss:  42652.446803388375\n",
      "[0.00091208 0.09562486 0.81623072 ... 0.15744487 0.20184326 0.55798445]\n",
      "logistic loss:  38128.732075639404\n",
      "[0.01027217 0.25593396 0.99895501 ... 0.25874635 0.47890467 0.65689888]\n",
      "logistic loss:  41942.30437536053\n",
      "[0.00132456 0.12901368 0.83503181 ... 0.15173883 0.25880934 0.54109317]\n",
      "logistic loss:  36361.63016001854\n",
      "[0.01509782 0.31972231 0.99891438 ... 0.25390536 0.55475397 0.64200373]\n",
      "logistic loss:  40738.45253620873\n",
      "[0.00184288 0.16529298 0.83167188 ... 0.1487423  0.31494833 0.52197366]\n",
      "logistic loss:  35184.42292500591\n",
      "[0.02190168 0.38791499 0.99892883 ... 0.25444691 0.62419422 0.62704934]\n",
      "logistic loss:  39990.68900718169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00237172 0.20349071 0.82776675 ... 0.14661313 0.36613702 0.49944095]\n",
      "logistic loss:  34192.775482804085\n",
      "[0.02908367 0.45032293 0.99888689 ... 0.2558937  0.67793908 0.60910026]\n",
      "logistic loss:  39291.68398267064\n",
      "[0.0029024  0.24226595 0.81953664 ... 0.14607431 0.41210187 0.47640134]\n",
      "logistic loss:  33439.41773674664\n",
      "[0.03671748 0.50791817 0.99885446 ... 0.2595051  0.72132589 0.59066333]\n",
      "logistic loss:  38763.05498540648\n",
      "[0.28491853 0.00336547 0.28019488 ... 0.0087306  0.7380958  0.22332864]\n",
      "logistic loss:  32403.221137328022\n",
      "[0.42508012 0.03958661 0.55647823 ... 0.04540669 0.81876921 0.31512921]\n",
      "logistic loss:  38064.132672686115\n",
      "[0.27106303 0.00315556 0.31486129 ... 0.00795395 0.72546131 0.22766138]\n",
      "logistic loss:  31843.21188360111\n",
      "[0.41298778 0.03928044 0.59282314 ... 0.04101769 0.81023442 0.32162766]\n",
      "logistic loss:  37205.802758813246\n",
      "[0.26498263 0.00343834 0.35070702 ... 0.00747555 0.71634217 0.2342747 ]\n",
      "logistic loss:  31650.168482274115\n",
      "[0.41047435 0.04650386 0.64068242 ... 0.04227783 0.80593139 0.33280221]\n",
      "logistic loss:  37561.61922912876\n",
      "[0.25338576 0.00328105 0.38059428 ... 0.00707219 0.70241541 0.23712617]\n",
      "logistic loss:  31155.476292792042\n",
      "[0.39778281 0.04399092 0.65715679 ... 0.03707483 0.79471705 0.33527977]\n",
      "logistic loss:  36187.21316003741\n",
      "[0.25360459 0.00390985 0.41225086 ... 0.00689436 0.69585154 0.24476701]\n",
      "logistic loss:  31372.947907106754\n",
      "[0.40509235 0.06018767 0.71046487 ... 0.04447196 0.79496441 0.35109876]\n",
      "logistic loss:  37979.35197463124\n",
      "max acc =  0.7427138140926443\n",
      "[0.50997098 0.95154864 0.99654394 ... 0.04085499 1.         0.86362701]\n",
      "logistic loss:  174386.24549798714\n",
      "[0.56691947 0.95101491 0.99581166 ... 0.07263007 1.         0.86410824]\n",
      "logistic loss:  155560.34916170867\n",
      "[0.61677504 0.95018668 0.99484978 ... 0.12046173 1.         0.86447562]\n",
      "logistic loss:  138303.49067482472\n",
      "[0.65844952 0.94904738 0.99357487 ... 0.18489978 1.         0.86462085]\n",
      "logistic loss:  122713.87286313617\n",
      "[0.69166601 0.94760086 0.99187298 ... 0.26195289 1.         0.86441767]\n",
      "logistic loss:  108849.01367794216\n",
      "[0.71666332 0.9458713  0.98959014 ... 0.34379394 0.99999999 0.86371171]\n",
      "logistic loss:  96710.08426173773\n",
      "[0.7338987  0.94389604 0.98652135 ... 0.42175867 0.99999993 0.8622963 ]\n",
      "logistic loss:  86273.57704749804\n",
      "[0.74375889 0.94171989 0.9823996  ... 0.48929466 0.99999958 0.85990793]\n",
      "logistic loss:  77473.5039565858\n",
      "[0.74645296 0.9393819  0.97689473 ... 0.54315301 0.99999779 0.85624625]\n",
      "logistic loss:  70179.28891203477\n",
      "[0.74215017 0.93688688 0.96963879 ... 0.58300961 0.99998974 0.85104705]\n",
      "logistic loss:  64212.31320082557\n",
      "[0.73105576 0.93421287 0.93798091 ... 0.99995811 0.07845696 0.84406468]\n",
      "logistic loss:  58996.40060184833\n",
      "[0.71529838 0.93191688 0.93656695 ... 0.99985121 0.04328341 0.83522239]\n",
      "logistic loss:  55074.37762568499\n",
      "[0.69377323 0.92931149 0.9335349  ... 0.99953607 0.02700632 0.82430647]\n",
      "logistic loss:  51852.14320538564\n",
      "[0.66787306 0.92626487 0.92906037 ... 0.99871964 0.01878684 0.81139691]\n",
      "logistic loss:  49154.0177933587\n",
      "[0.63919624 0.9226463  0.92327753 ... 0.99684524 0.01427585 0.79665461]\n",
      "logistic loss:  46859.55021759981\n",
      "[0.60927965 0.91834731 0.9162941  ... 0.99300594 0.01163622 0.78026763]\n",
      "logistic loss:  44887.82310796982\n",
      "[0.5794657  0.91329272 0.90821967 ... 0.9859529  0.0100254  0.76244732]\n",
      "logistic loss:  43181.441774607636\n",
      "[0.55082932 0.90742893 0.8991697  ... 0.97429624 0.00902375 0.74342219]\n",
      "logistic loss:  41697.8288661457\n",
      "[0.5241266  0.90071919 0.88926264 ... 0.95691997 0.00840804 0.72342753]\n",
      "logistic loss:  40403.358257851076\n",
      "[0.49979862 0.89314889 0.87862102 ... 0.93343402 0.00805212 0.70269863]\n",
      "logistic loss:  39269.780010856426\n",
      "[0.88472981 0.76934346 0.86737348 ... 0.02002817 0.90437843 0.00788061]\n",
      "logistic loss:  38078.564123933545\n",
      "[0.87555712 0.74906982 0.85457819 ... 0.02120367 0.86911611 0.00794028]\n",
      "logistic loss:  37189.40137486078\n",
      "[0.86553765 0.73048331 0.84153346 ... 0.02252469 0.83085161 0.00806694]\n",
      "logistic loss:  36406.73905004216\n",
      "[0.85475188 0.71361882 0.8283326  ... 0.02399055 0.79177116 0.00825888]\n",
      "logistic loss:  35714.76253110064\n",
      "[0.84329141 0.69844128 0.81507389 ... 0.02559979 0.75375201 0.0085134 ]\n",
      "logistic loss:  35100.53288978759\n",
      "[0.83125767 0.68486906 0.80185596 ... 0.02735017 0.71811931 0.00882744]\n",
      "logistic loss:  34553.37721496173\n",
      "[0.81875973 0.6727921  0.78877373 ... 0.02923862 0.68561985 0.00919786]\n",
      "logistic loss:  34064.42554589437\n",
      "[0.80591107 0.66208577 0.77591489 ... 0.0312612  0.65652776 0.00962157]\n",
      "logistic loss:  33626.2517065509\n",
      "[0.79282596 0.65262096 0.76335711 ... 0.03341314 0.63079058 0.01009555]\n",
      "logistic loss:  33232.5907077937\n",
      "[0.77961581 0.64427089 0.75116616 ... 0.03568888 0.60816091 0.01061682]\n",
      "logistic loss:  32878.11605797017\n",
      "[0.36690191 0.6369153  0.73939515 ... 0.0380821  0.01118242 0.48812086]\n",
      "logistic loss:  32789.16910389896\n",
      "[0.36585446 0.63203308 0.72769772 ... 0.04068786 0.01165909 0.47491811]\n",
      "logistic loss:  32494.013054698185\n",
      "[0.36470307 0.62758514 0.71635767 ... 0.04339958 0.01220947 0.46222222]\n",
      "logistic loss:  32228.016310619692\n",
      "[0.36363261 0.62356611 0.70548151 ... 0.04620086 0.01281448 0.45013231]\n",
      "logistic loss:  31987.559742953097\n",
      "[0.36273459 0.61995642 0.69512877 ... 0.04907878 0.0134618  0.43870853]\n",
      "logistic loss:  31769.642740319352\n",
      "[0.36204668 0.61672933 0.6853275  ... 0.05202255 0.01414307 0.42798259]\n",
      "logistic loss:  31571.709812353605\n",
      "[0.3615764  0.61385524 0.67608489 ... 0.05502262 0.01485229 0.41796535]\n",
      "logistic loss:  31391.556761686086\n",
      "[0.36131506 0.61130419 0.66739447 ... 0.05807018 0.01558482 0.40865241]\n",
      "logistic loss:  31227.26882461294\n",
      "[0.36124582 0.60904715 0.659241   ... 0.06115685 0.01633684 0.40002834]\n",
      "logistic loss:  31077.17429214168\n",
      "[0.3613483  0.60705683 0.6516038  ... 0.06427451 0.01710501 0.39206989]\n",
      "logistic loss:  30939.807522614414\n",
      "[1.         1.         1.         ... 0.99974184 1.         0.99999998]\n",
      "logistic loss:  670197.2258764264\n",
      "[0.99999834 0.99999948 0.99999999 ... 0.99062917 1.         0.99999537]\n",
      "logistic loss:  490696.7367231764\n",
      "[0.9988794  0.99987393 0.99999334 ... 0.76370661 1.         0.99884168]\n",
      "logistic loss:  298370.6628962039\n",
      "[8.57238777e-01 9.89734190e-01 9.98608272e-01 ... 1.94158696e-01\n",
      " 1.33678579e-28 9.12101798e-01]\n",
      "logistic loss:  153595.0068910984\n",
      "[4.23613424e-01 9.05460283e-01 9.75607176e-01 ... 8.08823213e-02\n",
      " 1.40172527e-54 5.92038916e-01]\n",
      "logistic loss:  91002.02572489265\n",
      "[3.82612263e-01 8.49426379e-01 9.60095088e-01 ... 9.25378635e-02\n",
      " 2.28646054e-63 5.26858741e-01]\n",
      "logistic loss:  77734.07150705768\n",
      "[5.09677021e-01 8.69326082e-01 9.72259954e-01 ... 1.42978668e-01\n",
      " 1.97838890e-65 6.19253520e-01]\n",
      "logistic loss:  71911.29636277126\n",
      "[5.85089759e-01 8.69810152e-01 9.77012856e-01 ... 1.91461722e-01\n",
      " 1.44981302e-67 6.75579450e-01]\n",
      "logistic loss:  67163.58314295035\n",
      "[6.30367862e-01 8.61842710e-01 9.79319917e-01 ... 2.36439240e-01\n",
      " 1.38192746e-69 7.14391568e-01]\n",
      "logistic loss:  63046.51772417271\n",
      "[6.56471785e-01 8.48311364e-01 9.80445293e-01 ... 2.76870188e-01\n",
      " 1.65478303e-71 7.42412363e-01]\n",
      "logistic loss:  59369.34560968662\n",
      "[6.70912875e-01 8.31034570e-01 7.32219907e-01 ... 2.64128486e-73\n",
      " 5.63534103e-03 7.63929571e-01]\n",
      "logistic loss:  55847.86582437116\n",
      "[6.75286428e-01 8.11780743e-01 7.29805933e-01 ... 2.74595813e-75\n",
      " 4.77640675e-03 7.77235682e-01]\n",
      "logistic loss:  52786.641811080866\n",
      "[6.83787969e-01 7.96956232e-01 7.31632398e-01 ... 1.28018000e-76\n",
      " 5.14407521e-03 7.93997253e-01]\n",
      "logistic loss:  50040.9659424925\n",
      "[6.81885476e-01 7.77035669e-01 7.27236060e-01 ... 5.16691181e-78\n",
      " 5.06116801e-03 8.04453288e-01]\n",
      "logistic loss:  47543.172903534316\n",
      "[6.79332343e-01 7.58063181e-01 7.23194468e-01 ... 3.79790410e-79\n",
      " 5.30033695e-03 8.14503701e-01]\n",
      "logistic loss:  45286.07784801097\n",
      "[6.72679851e-01 7.37544726e-01 7.16933923e-01 ... 3.32109028e-80\n",
      " 5.40459312e-03 8.22023235e-01]\n",
      "logistic loss:  43243.61406666657\n",
      "[6.65618980e-01 7.18056890e-01 7.10952560e-01 ... 4.43341659e-81\n",
      " 5.68477892e-03 8.29027506e-01]\n",
      "logistic loss:  41402.67392916637\n",
      "[6.56415334e-01 6.98215607e-01 7.03949388e-01 ... 7.20063246e-82\n",
      " 5.89891635e-03 8.34539107e-01]\n",
      "logistic loss:  39741.75861441762\n",
      "[6.47139435e-01 6.79517928e-01 6.97321416e-01 ... 1.60523758e-82\n",
      " 6.22991207e-03 8.39573410e-01]\n",
      "logistic loss:  38249.4421434354\n",
      "[6.36445100e-01 6.60840432e-01 6.90066530e-01 ... 4.18096800e-83\n",
      " 6.47237513e-03 8.43431858e-01]\n",
      "logistic loss:  36910.32770583448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.43503413e-01 9.75064666e-01 6.83337729e-01 ... 1.43150387e-01\n",
      " 1.41673424e-83 6.79205097e-03]\n",
      "logistic loss:  35656.61961499447\n",
      "[6.27000379e-01 9.73889162e-01 6.75327520e-01 ... 1.45663406e-01\n",
      " 3.28868035e-84 7.60695630e-03]\n",
      "logistic loss:  34599.51700264745\n",
      "[6.05288157e-01 9.71863746e-01 6.62677505e-01 ... 1.44033396e-01\n",
      " 4.02902560e-85 6.98459337e-03]\n",
      "logistic loss:  33656.44658827994\n",
      "[5.94637080e-01 9.71056460e-01 6.58819110e-01 ... 1.49267197e-01\n",
      " 1.32399877e-85 7.80995478e-03]\n",
      "logistic loss:  32822.35761296524\n",
      "[5.74971313e-01 9.68787999e-01 6.47339991e-01 ... 1.48084727e-01\n",
      " 2.17721375e-86 7.03648567e-03]\n",
      "logistic loss:  32074.10145263654\n",
      "[5.67845110e-01 9.68047346e-01 6.45659933e-01 ... 1.54718239e-01\n",
      " 1.10063451e-86 8.10384866e-03]\n",
      "logistic loss:  31412.68775797238\n",
      "[5.47777166e-01 9.65123880e-01 6.33088543e-01 ... 1.52153569e-01\n",
      " 2.04100285e-87 6.95530714e-03]\n",
      "logistic loss:  30814.55940289969\n",
      "[5.45873718e-01 9.64784940e-01 6.34813143e-01 ... 1.61313108e-01\n",
      " 1.75730154e-87 8.63372034e-03]\n",
      "logistic loss:  30288.7312279299\n",
      "[5.22360711e-01 9.60660694e-01 6.18586032e-01 ... 1.55259949e-01\n",
      " 2.80045471e-88 6.64010787e-03]\n",
      "logistic loss:  29808.073432299414\n",
      "[5.29404768e-01 9.61543787e-01 6.26840107e-01 ... 1.69740408e-01\n",
      " 5.32132488e-88 9.66984043e-03]\n",
      "logistic loss:  29398.2434752763\n",
      "[0.49194799 0.95494052 0.6020506  ... 0.15600877 0.00585476 0.83869274]\n",
      "logistic loss:  29383.211784544397\n",
      "[0.52553769 0.95990699 0.62443813 ... 0.18424127 0.01192842 0.85439778]\n",
      "logistic loss:  29138.41920766596\n",
      "[0.45765591 0.94743767 0.57453003 ... 0.1505392  0.00378219 0.8263158 ]\n",
      "logistic loss:  29036.850833347526\n",
      "[0.53964815 0.96072277 0.63361874 ... 0.21097404 0.01940273 0.8626592 ]\n",
      "logistic loss:  29237.056568472053\n",
      "[0.40215089 0.93179553 0.53293299 ... 0.13238584 0.0016327  0.80138336]\n",
      "logistic loss:  29751.092380080132\n",
      "[0.57312483 0.96385192 0.65871972 ... 0.25371496 0.03373024 0.87624731]\n",
      "logistic loss:  30520.474912471916\n",
      "[3.41500938e-01 9.07309352e-01 4.87934413e-01 ... 1.11216951e-01\n",
      " 4.93942235e-04 7.67959498e-01]\n",
      "logistic loss:  31502.166655795583\n",
      "[0.60187604 0.96565752 0.68245966 ... 0.29312849 0.0333447  0.8857586 ]\n",
      "logistic loss:  31595.025578471817\n",
      "[3.09699176e-01 8.86743798e-01 4.66064400e-01 ... 1.04307379e-01\n",
      " 2.66638956e-04 7.48450618e-01]\n",
      "logistic loss:  31946.13820165009\n",
      "[0.59938893 0.96292578 0.68486439 ... 0.30595906 0.02508829 0.88461658]\n",
      "logistic loss:  31509.553015814432\n",
      "[0.50997098 0.95154864 0.99654394 ... 0.04085499 1.         0.86362701]\n",
      "logistic loss:  174386.24549798714\n",
      "[0.56691947 0.95101488 0.99581165 ... 0.07263011 1.         0.8641082 ]\n",
      "logistic loss:  155560.31878015812\n",
      "[0.61677503 0.95018663 0.99484977 ... 0.12046185 1.         0.86447554]\n",
      "logistic loss:  138303.4322520169\n",
      "[0.65844947 0.9490473  0.99357485 ... 0.18490001 1.         0.86462072]\n",
      "logistic loss:  122713.79120076945\n",
      "[0.69166593 0.94760074 0.99187295 ... 0.26195322 1.         0.8644175 ]\n",
      "logistic loss:  108848.91336562793\n",
      "[0.71666319 0.94587115 0.98959009 ... 0.34379434 0.99999999 0.86371149]\n",
      "logistic loss:  96709.96909308102\n",
      "[0.73389851 0.94389586 0.98652126 ... 0.42175909 0.99999993 0.86229603]\n",
      "logistic loss:  86273.45181034098\n",
      "[0.74375863 0.94171967 0.98239947 ... 0.48929504 0.99999958 0.85990761]\n",
      "logistic loss:  77473.37335324053\n",
      "[0.74645262 0.93938163 0.97689455 ... 0.54315331 0.99999779 0.85624586]\n",
      "logistic loss:  70179.15641140405\n",
      "[0.74214972 0.93688658 0.96963854 ... 0.58300982 0.99998974 0.8510466 ]\n",
      "logistic loss:  64212.18156610154\n",
      "[0.73105519 0.93421253 0.93798059 ... 0.99995811 0.07845675 0.84406415]\n",
      "logistic loss:  58996.27224636747\n",
      "[0.71529768 0.93191648 0.93656658 ... 0.99985121 0.04328338 0.83522176]\n",
      "logistic loss:  55074.252435542876\n",
      "[0.69377239 0.92931105 0.93353446 ... 0.99953605 0.02700636 0.82430574]\n",
      "logistic loss:  51852.02119232337\n",
      "[0.66787211 0.92626438 0.92905985 ... 0.9987196  0.01878691 0.81139608]\n",
      "logistic loss:  49153.89889008737\n",
      "[0.6391952  0.92264574 0.92327694 ... 0.99684514 0.01427593 0.79665366]\n",
      "logistic loss:  46859.43450669599\n",
      "[0.60927855 0.91834668 0.91629341 ... 0.99300572 0.01163631 0.78026658]\n",
      "logistic loss:  44887.7107440041\n",
      "[0.57946457 0.91329201 0.90821888 ... 0.98595248 0.0100255  0.76244616]\n",
      "logistic loss:  43181.332943902395\n",
      "[0.55082821 0.90742813 0.89916881 ... 0.97429552 0.00902385 0.74342093]\n",
      "logistic loss:  41697.72374430395\n",
      "[0.52412553 0.9007183  0.88926164 ... 0.95691885 0.00840815 0.72342619]\n",
      "logistic loss:  40403.256956065416\n",
      "[0.49979761 0.8931479  0.87861992 ... 0.93343245 0.00805223 0.70269721]\n",
      "logistic loss:  39269.68256160524\n",
      "[0.88472871 0.76934194 0.86737227 ... 0.02002848 0.90437641 0.00788073]\n",
      "logistic loss:  38078.47085904045\n",
      "[0.87555591 0.74906828 0.85457688 ... 0.02120402 0.86911366 0.00794041]\n",
      "logistic loss:  37189.312070794454\n",
      "[0.86553632 0.73048178 0.84153205 ... 0.02252507 0.83084883 0.00806709]\n",
      "logistic loss:  36406.65362139902\n",
      "[0.85475044 0.71361731 0.8283311  ... 0.02399096 0.79176817 0.00825904]\n",
      "logistic loss:  35714.68087173516\n",
      "[0.84328986 0.69843981 0.81507231 ... 0.02560025 0.75374893 0.00851357]\n",
      "logistic loss:  35100.45488183631\n",
      "[0.83125602 0.68486764 0.80185431 ... 0.02735067 0.71811623 0.00882762]\n",
      "logistic loss:  34553.302733717566\n",
      "[0.81875798 0.67279072 0.78877202 ... 0.02923917 0.68561685 0.00919805]\n",
      "logistic loss:  34064.35446269479\n",
      "[0.80590923 0.66208444 0.77591314 ... 0.03126179 0.65652487 0.00962177]\n",
      "logistic loss:  33626.183890512504\n",
      "[0.79282404 0.65261969 0.76335533 ... 0.03341379 0.63078782 0.01009577]\n",
      "logistic loss:  33232.52602691237\n",
      "[0.77961383 0.64426966 0.75116436 ... 0.03568957 0.60815829 0.01061706]\n",
      "logistic loss:  32878.05437993229\n",
      "[0.36690175 0.63691412 0.73939335 ... 0.03808285 0.01118267 0.48811975]\n",
      "logistic loss:  32789.109838323726\n",
      "[0.36585435 0.63203196 0.7276959  ... 0.04068867 0.01165936 0.4749171 ]\n",
      "logistic loss:  32493.956620959878\n",
      "[0.36470299 0.62758406 0.71635586 ... 0.04340044 0.01220976 0.46222131]\n",
      "logistic loss:  32227.962568782637\n",
      "[0.36363257 0.62356507 0.70547972 ... 0.04620178 0.01281478 0.4501315 ]\n",
      "logistic loss:  31987.508553039203\n",
      "[0.36273457 0.61995541 0.695127   ... 0.04907976 0.01346211 0.43870783]\n",
      "logistic loss:  31769.59396611338\n",
      "[0.36204668 0.61672836 0.68532575 ... 0.05202358 0.01414341 0.427982  ]\n",
      "logistic loss:  31571.663322964076\n",
      "[0.36157642 0.6138543  0.67608316 ... 0.05502371 0.01485265 0.41796486]\n",
      "logistic loss:  31391.512432246833\n",
      "[0.3613151  0.61130327 0.66739277 ... 0.05807133 0.0155852  0.40865203]\n",
      "logistic loss:  31227.226536555612\n",
      "[0.36124587 0.60904626 0.65923935 ... 0.06115805 0.01633724 0.40002806]\n",
      "logistic loss:  31077.133933217294\n",
      "[0.36134836 0.60705597 0.65160218 ... 0.06427575 0.01710542 0.39206971]\n",
      "logistic loss:  30939.76898676454\n",
      "[1.         1.         1.         ... 0.99974184 1.         0.99999998]\n",
      "logistic loss:  670197.2258764264\n",
      "[0.99999834 0.99999948 0.99999999 ... 0.99062916 1.         0.99999537]\n",
      "logistic loss:  490696.639880638\n",
      "[0.99887939 0.99987393 0.99999334 ... 0.76370616 1.         0.99884167]\n",
      "logistic loss:  298370.4604936928\n",
      "[8.57238003e-01 9.89734114e-01 9.98608258e-01 ... 1.94158408e-01\n",
      " 1.33660837e-28 9.12101302e-01]\n",
      "logistic loss:  153594.81065882384\n",
      "[4.23612709e-01 9.05459817e-01 9.75606999e-01 ... 8.08823629e-02\n",
      " 1.40169732e-54 5.92038101e-01]\n",
      "logistic loss:  91001.89746234915\n",
      "[3.82612480e-01 8.49426123e-01 9.60094977e-01 ... 9.25381362e-02\n",
      " 2.28662182e-63 5.26858720e-01]\n",
      "logistic loss:  77733.98731877482\n",
      "[5.09677425e-01 8.69325884e-01 9.72259877e-01 ... 1.42979148e-01\n",
      " 1.97865559e-65 6.19253656e-01]\n",
      "logistic loss:  71911.20466022755\n",
      "[5.85089882e-01 8.69809816e-01 9.77012754e-01 ... 1.91462278e-01\n",
      " 1.45003424e-67 6.75579391e-01]\n",
      "logistic loss:  67163.48353172805\n",
      "[6.30367869e-01 8.61842291e-01 9.79319805e-01 ... 2.36439884e-01\n",
      " 1.38218668e-69 7.14391449e-01]\n",
      "logistic loss:  63046.411333710916\n",
      "[6.56471641e-01 8.48310828e-01 9.80445165e-01 ... 2.76870871e-01\n",
      " 1.65514611e-71 7.42412156e-01]\n",
      "logistic loss:  59369.233274618746\n",
      "[6.70912610e-01 8.31033919e-01 7.32219471e-01 ... 2.64195674e-73\n",
      " 5.63539076e-03 7.63929295e-01]\n",
      "logistic loss:  55847.74920459431\n",
      "[6.75286042e-01 8.11779971e-01 7.29805413e-01 ... 2.74675603e-75\n",
      " 4.77645398e-03 7.77235335e-01]\n",
      "logistic loss:  52786.52153982929\n",
      "[6.83787504e-01 7.96955382e-01 7.31631827e-01 ... 1.28060393e-76\n",
      " 5.14413471e-03 7.93996865e-01]\n",
      "logistic loss:  50040.84328172007\n",
      "[6.81884876e-01 7.77034696e-01 7.27235397e-01 ... 5.16881028e-78\n",
      " 5.06122888e-03 8.04452822e-01]\n",
      "logistic loss:  47543.04863520725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.79331668e-01 7.58062139e-01 7.23193756e-01 ... 3.79946013e-79\n",
      " 5.30040829e-03 8.14503193e-01]\n",
      "logistic loss:  45285.95303635285\n",
      "[6.72679060e-01 7.37543594e-01 7.16933132e-01 ... 3.32258036e-80\n",
      " 5.40466834e-03 8.22022660e-01]\n",
      "logistic loss:  43243.48955292275\n",
      "[6.65618127e-01 7.18055720e-01 7.10951732e-01 ... 4.43559896e-81\n",
      " 5.68486583e-03 8.29026892e-01]\n",
      "logistic loss:  41402.550393581216\n",
      "[6.56414377e-01 6.98214374e-01 7.03948492e-01 ... 7.20446097e-82\n",
      " 5.89900851e-03 8.34538429e-01]\n",
      "logistic loss:  39741.636622262406\n",
      "[6.47138424e-01 6.79516684e-01 6.97320489e-01 ... 1.60616063e-82\n",
      " 6.23001612e-03 8.39572690e-01]\n",
      "logistic loss:  38249.32232152608\n",
      "[6.36443995e-01 6.60839152e-01 6.90065544e-01 ... 4.18353676e-83\n",
      " 6.47248347e-03 8.43431071e-01]\n",
      "logistic loss:  36910.210603299856\n",
      "[6.43502154e-01 9.75064277e-01 6.83336727e-01 ... 1.43151200e-01\n",
      " 1.41766639e-83 6.79217075e-03]\n",
      "logistic loss:  35656.50594497529\n",
      "[6.26999108e-01 9.73888736e-01 6.75326468e-01 ... 1.45664260e-01\n",
      " 3.29097256e-84 7.60708945e-03]\n",
      "logistic loss:  34599.40676144251\n",
      "[6.05286890e-01 9.71863267e-01 6.62676414e-01 ... 1.44034275e-01\n",
      " 4.03199104e-85 6.98471409e-03]\n",
      "logistic loss:  33656.33993281099\n",
      "[5.94635920e-01 9.71055959e-01 6.58818063e-01 ... 1.49268190e-01\n",
      " 1.32503535e-85 7.81010353e-03]\n",
      "logistic loss:  32822.25460706596\n",
      "[5.74970068e-01 9.68787422e-01 6.47338823e-01 ... 1.48085666e-01\n",
      " 2.17898537e-86 7.03660326e-03]\n",
      "logistic loss:  32074.001992182075\n",
      "[5.67844117e-01 9.68046765e-01 6.45658918e-01 ... 1.54719383e-01\n",
      " 1.10159346e-86 8.10402177e-03]\n",
      "logistic loss:  31412.591955308435\n",
      "[5.47775910e-01 9.65123179e-01 6.33087251e-01 ... 1.52154520e-01\n",
      " 2.04281234e-87 6.95541124e-03]\n",
      "logistic loss:  30814.467020003896\n",
      "[5.45872998e-01 9.64784290e-01 6.34812233e-01 ... 1.61314465e-01\n",
      " 1.75899806e-87 8.63394059e-03]\n",
      "logistic loss:  30288.642815862844\n",
      "[5.22359310e-01 9.60659823e-01 6.18584503e-01 ... 1.55260802e-01\n",
      " 2.80310667e-88 6.64017437e-03]\n",
      "logistic loss:  29807.98895212022\n",
      "[5.29404542e-01 9.61543109e-01 6.26839489e-01 ... 1.69742150e-01\n",
      " 5.32703770e-88 9.67016763e-03]\n",
      "logistic loss:  29398.165195430694\n",
      "[0.49194537 0.95493937 0.60204856 ... 0.15600928 0.00585474 0.83869067]\n",
      "logistic loss:  29383.140969420125\n",
      "[0.52553812 0.95990642 0.6244383  ... 0.18424391 0.01192904 0.85439706]\n",
      "logistic loss:  29138.369384585807\n",
      "[0.45765169 0.94743596 0.57452682 ... 0.15053882 0.00378205 0.82631272]\n",
      "logistic loss:  29036.84125687852\n",
      "[0.53965103 0.96072254 0.63362074 ... 0.21097877 0.01940434 0.86265935]\n",
      "logistic loss:  29237.1171299793\n",
      "[0.40214427 0.93179253 0.53292793 ... 0.1323841  0.00163253 0.80137847]\n",
      "logistic loss:  29751.250741589694\n",
      "[0.5731299  0.96385197 0.65872342 ... 0.25372197 0.03373244 0.87624806]\n",
      "logistic loss:  30520.66268076348\n",
      "[3.41494777e-01 9.07305205e-01 4.87929661e-01 ... 1.11215491e-01\n",
      " 4.93884088e-04 7.67954018e-01]\n",
      "logistic loss:  31502.372197613655\n",
      "[0.6018792  0.96565723 0.68246213 ... 0.29313408 0.03334454 0.88575857]\n",
      "logistic loss:  31595.117337215695\n",
      "[3.09696258e-01 8.86740221e-01 4.66062246e-01 ... 1.04307468e-01\n",
      " 2.66627784e-04 7.48446869e-01]\n",
      "logistic loss:  31946.158072825056\n",
      "[0.59938911 0.96292504 0.68486476 ... 0.30596228 0.02508808 0.88461559]\n",
      "logistic loss:  31509.553593441422\n",
      "max acc =  0.7431348221670802\n",
      "Accuracy jet 0 = 0.8159180078469053\n",
      "Accuracy jet 1 = 0.7427138140926443\n",
      "Accuracy jet >1 = 0.7431348221670802\n"
     ]
    }
   ],
   "source": [
    "degrees=np.linspace(1,15,15)\n",
    "degrees=np.asarray(degrees)\n",
    "degrees=[1,2]\n",
    "lambdas=np.logspace(-5,-2,2)\n",
    "max_iter=10\n",
    "gamma=1e-5\n",
    "\n",
    "best_lambda_acc_0, best_degree_acc_0,max_acc_0 = logistic_hyperparam_with_CV(y0, x0, lambdas, gamma, degrees, max_iter)\n",
    "best_lambda_acc_1, best_degree_acc_1,max_acc_1 = logistic_hyperparam_with_CV(y1, x1, lambdas, gamma, degrees, max_iter)\n",
    "best_lambda_acc_2, best_degree_acc_2,max_acc_2 = logistic_hyperparam_with_CV(y2, x2, lambdas, gamma, degrees, max_iter)\n",
    "                     \n",
    "print('Accuracy jet 0 =', max_acc_0)\n",
    "print('Accuracy jet 1 =', max_acc_1)\n",
    "print('Accuracy jet >1 =', max_acc_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambdas0 = np.linspace(0.0001,0.01,15) #for the first subset the lambda is around 0.001\n",
    "# lambdas1 = np.linspace(0.00001,0.001,15) #for the second subset the lambda is around 0.0001\n",
    "# lambdas2 = np.linspace(0.00001,0.001,15) #for the third subset the lambda is around 0.0001\n",
    "\n",
    "# degrees = np.arange(7,17) #the best degree was high for all the models\n",
    "\n",
    "\n",
    "# best_lambda_loss0, best_degree_loss0, best_w_loss0, best_lambda_acc0, best_degree_acc0, best_w_acc0, loss_tr0, loss_te0, accuracy0 = \\\n",
    "# grid_search_hyperparam_with_CV(y0, x0, lambdas0, degrees)\n",
    "\n",
    "# best_lambda_loss1, best_degree_loss1, best_w_loss1, best_lambda_acc1, best_degree_acc1, best_w_acc1, loss_tr1, loss_te1, accuracy1 = \\\n",
    "# grid_search_hyperparam_with_CV(y1, x1, lambdas1, degrees)\n",
    "\n",
    "# best_lambda_loss2, best_degree_loss2, best_w_loss2, best_lambda_acc2, best_degree_acc2, best_w_acc2, loss_tr2, loss_te2, accuracy2 = \\\n",
    "# grid_search_hyperparam_with_CV(y2, x2, lambdas2, degrees)\n",
    "\n",
    "# print('LOSS')\n",
    "# print(f'Model with 0 jets: lambda = {best_lambda_loss0}, degree = {best_degree_loss0}, loss = {np.min(loss_te0)}')\n",
    "# print(f'Model with 1 jets: lambda = {best_lambda_loss1}, degree = {best_degree_loss1}, loss = {np.min(loss_te1)}')\n",
    "# print(f'Model with more than 1 jets: lambda = {best_lambda_loss2}, degree = {best_degree_loss2}, loss = {np.min(loss_te2)}')\n",
    "\n",
    "# print('\\n\\nACCURACY')\n",
    "# print(f'Model with 0 jets: lambda = {best_lambda_acc0}, degree = {best_degree_acc0}, acc = {np.max(accuracy0)}')\n",
    "# print(f'Model with 1 jets: lambda = {best_lambda_acc1}, degree = {best_degree_acc1}, acc = {np.max(accuracy1)}')\n",
    "# print(f'Model with more than 1 jets: lambda = {best_lambda_acc2}, degree = {best_degree_acc2}, acc = {np.max(accuracy2)}')\n",
    "\n",
    "\n",
    "# N0 = x0.shape[0]\n",
    "# N1 = x1.shape[0]\n",
    "# N2 = x2.shape[0]\n",
    "\n",
    "# TOTAccuracy = ( N0*np.max(accuracy0) + N1*np.max(accuracy1) + N2*np.max(accuracy2) ) / ( N0 + N1 + N2 )\n",
    "# print(f'\\n\\nOur test set reached an accuracy of: acc = {TOTAccuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission: import and basic steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = deepcopy(originalTest)\n",
    "num_tests = test_data.shape[0]\n",
    "\n",
    "numInvalidValues=countInvalid(test_data, -999)\n",
    "idxCols = np.where(numInvalidValues>0)[0]\n",
    "input_data = replaceWithZero(test_data,-999,idxCols)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jet division, removing constant/HC columns, standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x0, x1, x2\n",
    "idx0 = np.where(test_data[:,22]==0)\n",
    "idx1 = np.where(test_data[:,22]==1)\n",
    "idx2 = np.where(test_data[:,22]>=2)\n",
    "\n",
    "x0 = test_data[idx0] \n",
    "x1 = test_data[idx1] \n",
    "x2 = test_data[idx2] \n",
    "\n",
    "x0 = np.delete(x0, idx_constants_removed0, axis=1)\n",
    "x1 = np.delete(x1, idx_constants_removed1, axis=1)\n",
    "\n",
    "x0,_,_ = standardizeWithGivenParameters ( x0, mean_train0, std_train0 )\n",
    "x1,_,_ = standardizeWithGivenParameters ( x1, mean_train1, std_train1 )\n",
    "x2,_,_ = standardizeWithGivenParameters ( x2, mean_train2, std_train2 )\n",
    "\n",
    "if(HC_flag):\n",
    "    for i in idx_HC_removed0:\n",
    "        x0 = np.delete(x0,i,axis=1)\n",
    "    for i in idx_HC_removed1:\n",
    "        x1 = np.delete(x1,i,axis=1)\n",
    "    for i in idx_HC_removed2:\n",
    "        x2 = np.delete(x2,i,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat regression stuff and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = build_poly(x0, int(best_degree_acc0[0]))\n",
    "x1 = build_poly(x1, int(best_degree_acc1[0]))\n",
    "x2 = build_poly(x2, int(best_degree_acc2[0]))\n",
    "\n",
    "y_pred0 = predict_labels(best_w_acc0,x0)\n",
    "y_pred1 = predict_labels(best_w_acc1,x1)\n",
    "y_pred2 = predict_labels(best_w_acc2,x2)\n",
    "\n",
    "y_pred = np.ones(num_tests)\n",
    "y_pred[idx0] = y_pred0\n",
    "y_pred[idx1] = y_pred1\n",
    "y_pred[idx2] = y_pred2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_submission(ids_test, y_pred, 'dummy_name.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
