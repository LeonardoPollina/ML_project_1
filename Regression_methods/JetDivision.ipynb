{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import time \n",
    "\n",
    "#to keep things in order, and to avoid to copy and paste everytime our functions if we want to use them in more than one folder,\n",
    "#we can temporarily use this library. \n",
    "import sys\n",
    "\n",
    "#in this way Python will search the implementations also in the path '../HelperFunctions'\n",
    "sys.path.insert(0, '../HelperFunctions')\n",
    "sys.path.insert(0, '../pre-processing/Clean_Data/')\n",
    "\n",
    "from proj1_helpers import *\n",
    "from common_functions import *\n",
    "from counters import *\n",
    "from remove import *\n",
    "from replace import *\n",
    "from regressors import *\n",
    "from CrossValidationFunctions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CrossValidationFunctions import *\n",
    "def grid_search_hyperparam_with_CV(y, tx, lambdas, degrees):\n",
    "    loss_tr = np.zeros((len(lambdas), len(degrees)))\n",
    "    loss_te = np.zeros((len(lambdas), len(degrees)))\n",
    "    accuracy = np.zeros((len(lambdas), len(degrees)))\n",
    "    \n",
    "    for idx_lambda, lambda_ in enumerate(lambdas):\n",
    "        for idx_degree, degree in enumerate(degrees):\n",
    "                        \n",
    "            x_augmented = build_poly(tx, degree)\n",
    "            \n",
    "            #regression with your favourite method\n",
    "            k_indices = build_k_indices(y, 4, 1)\n",
    "            acc, loss1, loss2 = cross_validation_with_ridge(y, x_augmented, k_indices, lambda_)\n",
    "            \n",
    "            loss_tr[idx_lambda, idx_degree] = loss1\n",
    "            loss_te[idx_lambda, idx_degree] = loss2\n",
    "            accuracy[idx_lambda, idx_degree] = acc\n",
    "    \n",
    "    #find the best using the loss\n",
    "    min_loss_te = np.min(loss_te)\n",
    "    best_lambda_loss = lambdas[ np.where( loss_te == min_loss_te )[0] ]\n",
    "    best_degree_loss = degrees[ np.where( loss_te == min_loss_te )[1] ]\n",
    "\n",
    "    #recompute best w\n",
    "    x_augmented = build_poly(tx, int(best_degree_loss))\n",
    "    best_w_loss = ridge_regression(y,x_augmented,best_lambda_loss)\n",
    "    \n",
    "    #find the best using the accuracy\n",
    "    max_acc = np.max(accuracy)\n",
    "    best_lambda_acc = lambdas[ np.where( accuracy == max_acc )[0] ]\n",
    "    best_degree_acc = degrees[ np.where( accuracy == max_acc )[1] ]\n",
    "    \n",
    "    #recompute best w\n",
    "    x_augmented = build_poly(tx, int(best_degree_acc[0]))\n",
    "    best_w_acc = ridge_regression(y,x_augmented,best_lambda_acc[0])\n",
    "\n",
    "    return best_lambda_loss, best_degree_loss, best_w_loss, best_lambda_acc, best_degree_acc, best_w_acc, loss_tr, loss_te, accuracy\n",
    "\n",
    "\n",
    "def grid_search_hyperparam_RIDGE(y, tx, lambdas, degrees):\n",
    "    loss_tr = np.zeros((len(lambdas), len(degrees)))\n",
    "    loss_te = np.zeros((len(lambdas), len(degrees)))\n",
    "    \n",
    "    seed = 1\n",
    "    \n",
    "    for idx_lambda, lambda_ in enumerate(lambdas):\n",
    "        for idx_degree, degree in enumerate(degrees):\n",
    "            \n",
    "            x_augmented = build_poly(tx, degree)\n",
    "            \n",
    "            #regression with your favourite method\n",
    "            x_tr, x_te, y_tr, y_te = split_data(x_augmented, y, 0.7, seed = seed)\n",
    "\n",
    "            weights = ridge_regression(y_tr, x_tr, lambda_)\n",
    "\n",
    "            rmse_tr= np.sqrt(2 * compute_loss_MSE(y_tr, x_tr, weights))\n",
    "            rmse_vt= np.sqrt(2 * compute_loss_MSE(y_te, x_te, weights))\n",
    "            loss_tr[idx_lambda, idx_degree] = rmse_tr\n",
    "            loss_te[idx_lambda, idx_degree] = rmse_vt\n",
    "        \n",
    "    min_loss_te = np.min(loss_te)\n",
    "    best_lambda = lambdas[ np.where( loss_te == min_loss_te )[0] ]\n",
    "    best_degree = degrees[ np.where( loss_te == min_loss_te )[1] ]\n",
    "\n",
    "    #recompute best w\n",
    "    x_augmented = build_poly(tx, int(best_degree))\n",
    "    best_w = ridge_regression(y,x_augmented,best_lambda)\n",
    "\n",
    "    return best_lambda, best_degree, best_w, loss_tr, loss_te"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data And Basic Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1. -1. -1. ...  1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "yb, input_data, ids = load_csv_data(\"../data/train.csv\", sub_sample=False)\n",
    "_, test_data, ids_test = load_csv_data(\"../data/test.csv\", sub_sample=False)\n",
    "\n",
    "#this will surely be deleted, in this way we are sure that original_data is the original version of the data and we don't have\n",
    "#to load them again\n",
    "from copy import deepcopy\n",
    "originalData = deepcopy(input_data)\n",
    "originalY = deepcopy(yb)\n",
    "originalTest = deepcopy(test_data)\n",
    "print(yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic step\n",
    "input_data = deepcopy(originalData)\n",
    "numInvalidValues=countInvalid(input_data, -999)\n",
    "idxCols = np.where(numInvalidValues>0)[0]\n",
    "input_data = replaceWithZero(input_data,-999,idxCols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jet division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute 0 with 0.0001\n",
      "Substitute 0 with 0.0001\n"
     ]
    }
   ],
   "source": [
    "# x0, x1, x2\n",
    "idx0 = np.where(input_data[:,22]==0)\n",
    "idx1 = np.where(input_data[:,22]==1)\n",
    "idx2 = np.where(input_data[:,22]>=2)\n",
    "\n",
    "x0,_,_ = standardize ( input_data[idx0] )\n",
    "x1,_,_ = standardize ( input_data[idx1] )\n",
    "x2,_,_ = standardize ( input_data[idx2] )\n",
    "y0 = yb[idx0]\n",
    "y1 = yb[idx1]\n",
    "y2 = yb[idx2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression with CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with 0 jets: lambda = [0.001], degree = [1], loss = 0.7378892476990272\n",
      "Model with 1 jets: lambda = [0.001], degree = [5], loss = 0.8050446178537408\n",
      "Model with more than 1 jets: lambda = [0.001], degree = [3], loss = 0.7963036673060457\n"
     ]
    }
   ],
   "source": [
    "lambdas = np.logspace(-6,0,5)\n",
    "degrees = np.arange(14)\n",
    "\n",
    "best_lambda_loss0, best_degree_loss0, best_w_loss0, best_lambda_acc0, best_degree_acc0, best_w_acc0, loss_tr0, loss_te0, accuracy0 = \\\n",
    "grid_search_hyperparam(y0, x0 ,lambdas,degrees)\n",
    "\n",
    "best_lambda_loss1, best_degree_loss1, best_w_loss1, best_lambda_acc1, best_degree_acc1, best_w_acc1, loss_tr1, loss_te1, accuracy1 = \\\n",
    "grid_search_hyperparam(y1, x1 ,lambdas,degrees)\n",
    "\n",
    "best_lambda_loss2, best_degree_loss2, best_w_loss2, best_lambda_acc2, best_degree_acc2, best_w_acc2, loss_tr2, loss_te2, accuracy2 = \\\n",
    "grid_search_hyperparam(y2, x2 ,lambdas,degrees)\n",
    "\n",
    "\n",
    "print(f'Model with 0 jets: lambda = {best_lambda_loss0}, degree = {best_degree_loss0}, loss = {np.min(loss_te0)}')\n",
    "print(f'Model with 1 jets: lambda = {best_lambda_loss1}, degree = {best_degree_loss1}, loss = {np.min(loss_te1)}')\n",
    "print(f'Model with more than 1 jets: lambda = {best_lambda_loss2}, degree = {best_degree_loss2}, loss = {np.min(loss_te2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with 0 jets: lambda = [0.001], degree = [12], acc = 0.8427416126191047\n",
      "Model with 1 jets: lambda = [0.001], degree = [12], acc = 0.8065098524708554\n",
      "Model with more than 1 jets: lambda = [0.001 0.001], degree = [12 13], acc = 0.832078853046595\n"
     ]
    }
   ],
   "source": [
    "print(f'Model with 0 jets: lambda = {best_lambda_acc0}, degree = {best_degree_acc0}, acc = {np.max(accuracy0)}')\n",
    "print(f'Model with 1 jets: lambda = {best_lambda_acc1}, degree = {best_degree_acc1}, acc = {np.max(accuracy1)}')\n",
    "print(f'Model with more than 1 jets: lambda = {best_lambda_acc2}, degree = {best_degree_acc2}, acc = {np.max(accuracy2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with 0 jets: lambda = [0.00215443], degree = [1], loss = 0.7371577566715111\n",
      "Model with 1 jets: lambda = [0.00215443], degree = [5], loss = 0.8072869429323377\n",
      "Model with more than 1 jets: lambda = [0.01], degree = [7], loss = 0.7668980459553653\n"
     ]
    }
   ],
   "source": [
    "lambdas = np.logspace(-6,0,10)\n",
    "degrees = np.arange(10)\n",
    "\n",
    "best_lambda0, best_degree0, best_w0, loss_tr0, loss_te0 = grid_search_hyperparam_RIDGE(y0, x0 ,lambdas,degrees)\n",
    "best_lambda1, best_degree1, best_w1, loss_tr1, loss_te1 = grid_search_hyperparam_RIDGE(y1, x1 ,lambdas,degrees)\n",
    "best_lambda2, best_degree2, best_w2, loss_tr2, loss_te2 = grid_search_hyperparam_RIDGE(y2, x2 ,lambdas,degrees)\n",
    "\n",
    "\n",
    "print(f'Model with 0 jets: lambda = {best_lambda0}, degree = {best_degree0}, loss = {np.min(loss_te0)}')\n",
    "print(f'Model with 1 jets: lambda = {best_lambda1}, degree = {best_degree1}, loss = {np.min(loss_te1)}')\n",
    "print(f'Model with more than 1 jets: lambda = {best_lambda2}, degree = {best_degree2}, loss = {np.min(loss_te2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substitute 0 with 0.0001\n",
      "Substitute 0 with 0.0001\n"
     ]
    }
   ],
   "source": [
    "test_data = deepcopy(originalTest)\n",
    "num_tests = test_data.shape[0]\n",
    "\n",
    "# x0, x1, x2\n",
    "idx0 = np.where(test_data[:,22]==0)\n",
    "idx1 = np.where(test_data[:,22]==1)\n",
    "idx2 = np.where(test_data[:,22]>=2)\n",
    "\n",
    "x0,_,_ = standardize ( test_data[idx0] )\n",
    "x1,_,_ = standardize ( test_data[idx1] )\n",
    "x2,_,_ = standardize ( test_data[idx2] )\n",
    "\n",
    "x0 = build_poly(x0, int(best_degree0))\n",
    "x1 = build_poly(x1, int(best_degree1))\n",
    "x2 = build_poly(x2, int(best_degree2))\n",
    "\n",
    "y_pred0 = predict_labels(best_w0,x0)\n",
    "y_pred1 = predict_labels(best_w1,x1)\n",
    "y_pred2 = predict_labels(best_w2,x2)\n",
    "\n",
    "y_pred = np.ones(num_tests)\n",
    "y_pred[idx0] = y_pred0\n",
    "y_pred[idx1] = y_pred1\n",
    "y_pred[idx2] = y_pred2\n",
    "\n",
    "create_csv_submission(ids_test, y_pred, '999to0andDivisionPerJet20DegreeAccuracy.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
